{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking at ../data/products_books_v1_10_10.csv\n",
      "381082\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eaba468d-6226-4d3d-84b2-23796812a7bc</td>\n",
       "      <td>276847</td>\n",
       "      <td>0446364193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eaba468d-6226-4d3d-84b2-23796812a7bc</td>\n",
       "      <td>276847</td>\n",
       "      <td>3379015180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eaba468d-6226-4d3d-84b2-23796812a7bc</td>\n",
       "      <td>276847</td>\n",
       "      <td>3404148576</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eaba468d-6226-4d3d-84b2-23796812a7bc</td>\n",
       "      <td>276847</td>\n",
       "      <td>3423071516</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eaba468d-6226-4d3d-84b2-23796812a7bc</td>\n",
       "      <td>276847</td>\n",
       "      <td>3442413508</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  user_id  product_id  rate\n",
       "0  eaba468d-6226-4d3d-84b2-23796812a7bc   276847  0446364193     0\n",
       "1  eaba468d-6226-4d3d-84b2-23796812a7bc   276847  3379015180     0\n",
       "2  eaba468d-6226-4d3d-84b2-23796812a7bc   276847  3404148576     8\n",
       "3  eaba468d-6226-4d3d-84b2-23796812a7bc   276847  3423071516    10\n",
       "4  eaba468d-6226-4d3d-84b2-23796812a7bc   276847  3442413508    10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "import random\n",
    "import pickle\n",
    "import pprint\n",
    "import spacy\n",
    "\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "\n",
    "product_data = {\n",
    "    \"data_context\": \"books\",\n",
    "    \"product_filepath\": \"data/products_books_v1_10_10.csv\",\n",
    "    \"transactions_filepath\": \"data/transactions_books_v1_10_10.csv\",\n",
    "    \"features\": [\"product_title\", \"product_image\", \"product_soup\", \"product_images\"],\n",
    "    \"version\": \"1.0\",\n",
    "    \"unique_name\": \"_books_v1_10_10\",\n",
    "}\n",
    "\n",
    "print(\"looking at\", \"../\" + product_data[\"product_filepath\"])\n",
    "\n",
    "productdf =  pd.read_csv(\"../\" + product_data[\"product_filepath\"])\n",
    "transactiondf = pd.read_csv(\"../\" + product_data[\"transactions_filepath\"])\n",
    "\n",
    "\n",
    "print(len(transactiondf))\n",
    "productdf.head()\n",
    "transactiondf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RecommendationAbstract():\n",
    "    strategy_name: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    version: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_past_recommendation: bool = \"REQUIRES IMPLEMENTATION\"\n",
    "\n",
    "    def __init__(self, products, product_data):\n",
    "        self.products = products\n",
    "        self.product_data = product_data\n",
    "        self.model = None\n",
    "        # populate id_to_products\n",
    "        self.id_to_products = {}\n",
    "        for product in self.products.to_dict(orient='records'):\n",
    "            self.id_to_products[product['id']] = product\n",
    "\n",
    "    def loadModel(self, model_code):\n",
    "        \"\"\"\n",
    "        Load the model\n",
    "        \"\"\"\n",
    "        self.model = model_code\n",
    "\n",
    "    def train(self, verbose=False, transactions_train=None, users_train=None):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        # ... do training\n",
    "        # self.model = trained_model\n",
    "        \n",
    "    def get_random_recommendation(self, n=1):\n",
    "        \"\"\"\n",
    "        Get random recommendations\n",
    "        \"\"\"\n",
    "        # Select n random rows from the DataFrame\n",
    "        random_rows = self.products.sample(n)\n",
    "        # Convert the selected rows to a list of dictionaries\n",
    "        random_recommendations = random_rows.to_dict(orient='records')\n",
    "        return random_recommendations\n",
    "\n",
    "\n",
    "\n",
    "    def saveModel(self, model_code):\n",
    "        \"\"\"\n",
    "        Save the model\n",
    "        \"\"\"\n",
    "        # ... saves the model\n",
    "\n",
    "    def id_to_productDetail(self, product_id: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Return product details based on product id.\n",
    "        \"\"\"\n",
    "        return self.id_to_products.get(product_id)\n",
    "\n",
    "    def ids_to_products(self, ids: List[str]) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Return product details for a list of product ids.\n",
    "        \"\"\"\n",
    "        return [self.id_to_productDetail(id) for id in ids]\n",
    "\n",
    "    def like(self, keyword: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return a list of products that contain the given keyword in their title.\n",
    "        \"\"\"\n",
    "        return [product for product in self.products if keyword in product['product_title']]\n",
    "\n",
    "    def recommend_from_single(self, product_id: str, n=5) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        target_name = self.id_to_productDetail(product_id)['product_title']\n",
    "        keywords = target_name.split(\" \")\n",
    "        recommendations = []\n",
    "        for keyword in keywords:\n",
    "            recommendations.extend(self.like(keyword))\n",
    "        \n",
    "        random.shuffle(recommendations)\n",
    "        return recommendations[:n]\n",
    "\n",
    "    def recommend_from_past(self, user_transactions, n=10) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return recommendations based on past user transactions.\n",
    "        \"\"\"\n",
    "        rec = []\n",
    "        for transaction in user_transactions:\n",
    "            rec.extend(self.recommend_from_single(transaction['product_id']))\n",
    "        random.shuffle(rec)\n",
    "        return rec[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the class using cosine Similarity.\n",
    "\n",
    "class CosineSimilarityRecommender(RecommendationAbstract):\n",
    "    strategy_name: str = \"Cosine Similarity\"\n",
    "    slug_name: str = \"cosine_similarity\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data):\n",
    "        super().__init__(products, product_data)\n",
    "        self.products = products\n",
    "        self.pt = []\n",
    "        self.sim_score = None\n",
    "        \n",
    "    def train(self, transactions, auto_save=True):\n",
    "        self.pt = transactions.pivot_table(index=\"product_id\", columns=\"user_id\", values=\"rate\")\n",
    "        self.pt.fillna(0, inplace=True)\n",
    "        self.sim_score = cosine_similarity(self.pt)\n",
    "        if auto_save:\n",
    "            self.save()\n",
    "        \n",
    "        \n",
    "    def get_filename(self):\n",
    "        return \"models/\" + self.slug_name + self.product_data[\"unique_name\"] + \".pik\"\n",
    "    \n",
    "    def save(self):\n",
    "        # Store self.pt\n",
    "        filename = self.get_filename()\n",
    "        file_simscr = open(filename, 'wb')\n",
    "        pickle.dump(self.sim_score, file_simscr)\n",
    "        file_simscr.close()\n",
    "        \n",
    "    def load(self):\n",
    "        filename = self.get_filename()\n",
    "        file_simscr = open(filename, 'rb')\n",
    "        self.sim_score = pickle.load(file_simscr)\n",
    "        file_simscr.close()\n",
    "        \n",
    "\n",
    "    def recommend_from_single(self, product_id, n=5) -> List[Tuple[dict, float]]:\n",
    "        # Find the index of the product_id in the DataFrame\n",
    "        index = np.where(self.products['id'] == product_id)[0][0]\n",
    "        \n",
    "        # Get similarity scores for the product at the found index\n",
    "        similar_products = sorted(enumerate(self.sim_score[index]), key=lambda x: x[1], reverse=True)[1:n+1]\n",
    "        \n",
    "        # Retrieve the similar products using their indices and return them\n",
    "        recommendations_list = []\n",
    "        for similar_product in similar_products:\n",
    "            product_index, score = similar_product\n",
    "            product_dict = self.products.iloc[product_index].to_dict()\n",
    "            recommendations_list.append((product_dict, score))\n",
    "        \n",
    "        return recommendations_list\n",
    "\n",
    "\n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        rec: List[tuple[dict, float]] = []\n",
    "        for transaction in transactions:\n",
    "            rec.extend(self.recommend_from_single(transaction))\n",
    "        \n",
    "        # Sort by the confidence (second parameter of tuple)\n",
    "        sorted_rec: List[tuple[dict, float]] = sorted(rec, key=lambda x: x[1], reverse=True)\n",
    "        return sorted_rec[:n]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "cosineRecommender = CosineSimilarityRecommender(productdf, product_data)\n",
    "# Train.\n",
    "# cosineRecommender.train(transactiondf, auto_save=True)\n",
    "cosineRecommender.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0786869054',\n",
      " 'product_image': 'http://images.amazon.com/images/P/0786869054.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': 'The Sunday Wife: A Novel Cassandra King Hyperion',\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'The Sunday Wife: A Novel'}\n",
      "======== RECOMENDATIONS SINGLE CASE =========== \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'id': '0395683297',\n",
       "   'product_title': 'Silent Spring',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0395683297.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Silent Spring Rachel Carson Mariner Books',\n",
       "   'product_tags': nan},\n",
       "  0.39823291210564526),\n",
       " ({'id': '0425175413',\n",
       "   'product_title': 'The White House Connection',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0425175413.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'The White House Connection Jack Higgins Berkley Publishing Group',\n",
       "   'product_tags': nan},\n",
       "  0.38631440705543546),\n",
       " ({'id': '0743428188',\n",
       "   'product_title': 'The Twentieth Wife: A Novel',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0743428188.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'The Twentieth Wife: A Novel Indu Sundaresan Washington Square Press',\n",
       "   'product_tags': nan},\n",
       "  0.3584070796460177),\n",
       " ({'id': '0826308791',\n",
       "   'product_title': 'The Education of Little Tree (A Zia Book)',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0826308791.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'The Education of Little Tree (A Zia Book) Forrest Carter University of New Mexico Press',\n",
       "   'product_tags': nan},\n",
       "  0.3463933699983938),\n",
       " ({'id': '0553278118',\n",
       "   'product_title': 'Doctors',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0553278118.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Doctors Erich Segal Bantam Books',\n",
       "   'product_tags': nan},\n",
       "  0.3325950526188697)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use JSON parse.\n",
    "# cosineRecommender.get_random_recommendation()\n",
    "randomProduct = cosineRecommender.get_random_recommendation()[0]\n",
    "pprint.pprint(randomProduct)\n",
    "\n",
    "\n",
    "print('======== RECOMENDATIONS SINGLE CASE =========== ')\n",
    "cosineRecommender.recommend_from_single(randomProduct['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============  RECOMENDATIONS RECOMMENDATIONS  ============\n",
      "[({'id': '0440225922',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0440225922.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'The Poyson Garden: An Elizabethan I Mystery (Elizabeth I '\n",
      "                   'Mysteries (Paperback)) Karen Harper Dell Publishing '\n",
      "                   'Company',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'The Poyson Garden: An Elizabethan I Mystery (Elizabeth I '\n",
      "                    'Mysteries (Paperback))'},\n",
      "  0.6555859867761229),\n",
      " ({'id': '1853260193',\n",
      "   'product_image': 'http://images.amazon.com/images/P/1853260193.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Vanity Fair (Wordsworth Collection) William Makepeace '\n",
      "                   'Thackeray NTC/Contemporary Publishing Company',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Vanity Fair (Wordsworth Collection)'},\n",
      "  0.5928693837112383),\n",
      " ({'id': '0553574132',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0553574132.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Star Wars: Shadows of the Empire Steve Perry Spectra Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Star Wars: Shadows of the Empire'},\n",
      "  0.529326836824829),\n",
      " ({'id': '0060549270',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0060549270.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': \"A Greek God at the Ladies' Club (Avon Romance) Jenna \"\n",
      "                   'McKnight Avon',\n",
      "   'product_tags': nan,\n",
      "   'product_title': \"A Greek God at the Ladies' Club (Avon Romance)\"},\n",
      "  0.5109577868520863),\n",
      " ({'id': '0671496174',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0671496174.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': \"Robert Frost's Poems Robert Frost Pocket Books\",\n",
      "   'product_tags': nan,\n",
      "   'product_title': \"Robert Frost's Poems\"},\n",
      "  0.5104293552545828),\n",
      " ({'id': '0449220184',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0449220184.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Seventh Heaven Alice Hoffman Fawcett Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Seventh Heaven'},\n",
      "  0.2944922133381699),\n",
      " ({'id': '0312311338',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0312311338.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': \"McCarthy's Bar: A Journey of Discovery In Ireland Pete \"\n",
      "                   \"McCarthy St. Martin's Griffin\",\n",
      "   'product_tags': nan,\n",
      "   'product_title': \"McCarthy's Bar: A Journey of Discovery In Ireland\"},\n",
      "  0.27068105426879646),\n",
      " ({'id': '0425094731',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0425094731.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'The Dream Lover Lawrence Sanders Berkley Publishing Group',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'The Dream Lover'},\n",
      "  0.25242189714700275),\n",
      " ({'id': '1573228281',\n",
      "   'product_image': 'http://images.amazon.com/images/P/1573228281.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'A Gesture Life Chang-Rae Lee Riverhead Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'A Gesture Life'},\n",
      "  0.2428930837786301),\n",
      " ({'id': '0517605171',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0517605171.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Anne of Green Gables: Three Volumes in One L. M. '\n",
      "                   'Montgomery Random House Value Pub',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Anne of Green Gables: Three Volumes in One'},\n",
      "  0.22276803101723266)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ... Repetition.\n",
    "print(\"=============  RECOMENDATIONS RECOMMENDATIONS  ============\")\n",
    "tansactions = ['0590353403', '0439139597']\n",
    "\n",
    "rec_id = cosineRecommender.recommend_from_past(tansactions)\n",
    "pprint.pprint(rec_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class WordVecBodyRecommender(RecommendationAbstract):\n",
    "    \n",
    "    strategy_name: str = \"WordVec\"\n",
    "    slug_name: str = \"wordvec\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data):\n",
    "        \"\"\"\n",
    "        Initialize the recommender with a pre-trained Word2Vec model and a dataframe of books.\n",
    "        \"\"\"\n",
    "        super().__init__(products, product_data)\n",
    "        self.products_df = products\n",
    "        self.model = None\n",
    "        print('id_to_products length', len(self.id_to_products))\n",
    "        self.train()\n",
    "\n",
    "\n",
    "    def train(self, auto_save=True):\n",
    "        \"\"\"\n",
    "        Train the Word2Vec model on the book titles.\n",
    "        \"\"\"\n",
    "        sentences = [title.lower().split() for title in self.products_df['product_soup']]\n",
    "        self.model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "        if auto_save:\n",
    "            self.save()\n",
    "            \n",
    "\n",
    "    def recommend_books_updated(self, input_text, top_n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on input text.\n",
    "        \"\"\"\n",
    "        input_text = input_text.lower().split()\n",
    "        vector = self.model.wv[input_text].mean(axis=0)\n",
    "        # Compute cosine similarity between the input vector and all product vectors\n",
    "        similarities = cosine_similarity([vector], self.model.wv.vectors)\n",
    "        # Get indices of top similar products\n",
    "        top_indices = similarities.argsort()[0][-top_n:]\n",
    "        recommended_products = []\n",
    "        for index in reversed(top_indices):  # Reversed to get top similarities first\n",
    "            product_title = self.products_df.iloc[index]['product_title']\n",
    "            confidence = similarities[0][index]\n",
    "            recommended_products.append((self.id_to_productDetail(self.products_df.iloc[index]['id']), confidence))\n",
    "        return recommended_products\n",
    "\n",
    "        \n",
    "    def recommend_from_single(self, product_id, n=5) -> List[tuple[dict, float]]:\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        # Get the product_soup for the given product_id\n",
    "        product_soup = self.products.loc[self.products['id'] == product_id, 'product_soup'].values[0]\n",
    "        # Use the recommend_books_updated function to recommend books based on the product_soup\n",
    "        recommendations = self.recommend_books_updated(product_soup, top_n=n)\n",
    "        return recommendations\n",
    "\n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        \"\"\"\n",
    "        Return recommendations based on past transactions.\n",
    "        \"\"\"\n",
    "        # Concatenate product_soup from past transactions\n",
    "        past_text = ' '.join(self.products.loc[self.products['id'].isin(transactions), 'product_soup'])\n",
    "        # Use the self.recommend_books_updated function to recommend books based on past transactions\n",
    "        recommendations = self.recommend_books_updated(past_text, top_n=n)\n",
    "        return recommendations\n",
    "        \n",
    "        \n",
    "    def get_filename(self):\n",
    "        return  \"models/\" + self.slug_name + self.product_data[\"unique_name\"] + \".model\"\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save the computed book vectors to a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        filemodel = open(filename, 'wb')\n",
    "        pickle.dump(self.model, filemodel)\n",
    "        filemodel.close()\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load the book vectors from a file.\n",
    "        \"\"\"\n",
    "        \n",
    "        filename = self.get_filename()\n",
    "        filemodel = open(filename, 'rb')\n",
    "        self.model = pickle.load(filemodel)\n",
    "        filemodel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_to_products length 13011\n"
     ]
    }
   ],
   "source": [
    "# Implementationa nd test.\n",
    "\n",
    "wordvecRecommender = WordVecBodyRecommender(productdf, product_data)\n",
    "# Train.\n",
    "# wordvecRecommender.train()\n",
    "wordvecRecommender.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0060391553',\n",
      " 'product_image': 'http://images.amazon.com/images/P/0060391553.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': 'Enter Whining Fran Drescher Harpercollins',\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'Enter Whining'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'id': '0553584383',\n",
       "   'product_title': 'Dead Aim',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0553584383.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Dead Aim IRIS JOHANSEN Bantam Books',\n",
       "   'product_tags': nan},\n",
       "  0.99974954),\n",
       " ({'id': '0060925000',\n",
       "   'product_title': 'A Suitable Boy : Novel, A',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0060925000.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'A Suitable Boy : Novel, A Vikram Seth Perennial',\n",
       "   'product_tags': nan},\n",
       "  0.9983109),\n",
       " ({'id': '193072229X',\n",
       "   'product_title': \"MoveOn's 50 Ways to Love Your Country: How to Find Your Political Voice and Become a Catalyst for Change\",\n",
       "   'product_image': 'http://images.amazon.com/images/P/193072229X.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': \"MoveOn's 50 Ways to Love Your Country: How to Find Your Political Voice and Become a Catalyst for Change Moveon Inner Ocean Publishing\",\n",
       "   'product_tags': nan},\n",
       "  0.9982143),\n",
       " ({'id': '0375420827',\n",
       "   'product_title': 'The Art of Travel',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0375420827.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'The Art of Travel Alain de Botton Pantheon',\n",
       "   'product_tags': nan},\n",
       "  0.99814373),\n",
       " ({'id': '0399144463',\n",
       "   'product_title': 'Who Moved My Cheese? An Amazing Way to Deal with Change in Your Work and in Your Life',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0399144463.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Who Moved My Cheese? An Amazing Way to Deal with Change in Your Work and in Your Life Spencer Johnson Putnam Pub Group (Paper)',\n",
       "   'product_tags': nan},\n",
       "  0.99796)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get random and recommend.\n",
    "\n",
    "randomProduct = wordvecRecommender.get_random_recommendation()[0]\n",
    "pprint.pprint(randomProduct)\n",
    "wordvecRecommender.recommend_from_single(randomProduct['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============  RECOMENDATIONS RECOMMENDATIONS  ============\n",
      "[({'id': '0385490992',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0385490992.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'The Street Lawyer John Grisham Doubleday Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'The Street Lawyer'},\n",
      "  0.9987477),\n",
      " ({'id': '0345313097',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0345313097.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Crewel Lye Piers Anthony Ballantine Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Crewel Lye'},\n",
      "  0.9985696),\n",
      " ({'id': '0385418493',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0385418493.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'How the Irish Saved Civilization: The Untold Story of '\n",
      "                   \"Ireland's Heroic Role from the Fall of Rome to the Rise of \"\n",
      "                   'Medieval Europe (Hinges of History) Thomas Cahill Anchor',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'How the Irish Saved Civilization: The Untold Story of '\n",
      "                    \"Ireland's Heroic Role from the Fall of Rome to the Rise \"\n",
      "                    'of Medieval Europe (Hinges of History)'},\n",
      "  0.9985447),\n",
      " ({'id': '0441004016',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0441004016.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'The Anubis Gates Tim Powers Ace Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'The Anubis Gates'},\n",
      "  0.998541),\n",
      " ({'id': '0452282152',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0452282152.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Girl with a Pearl Earring Tracy Chevalier Plume Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Girl with a Pearl Earring'},\n",
      "  0.99845946),\n",
      " ({'id': '0385316895',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0385316895.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Legacy of Silence Belva Plain Bantam Dell Pub Group',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Legacy of Silence'},\n",
      "  0.99840194),\n",
      " ({'id': '0345313860',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0345313860.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'The Vampire Lestat (Vampire Chronicles, Book II) ANNE RICE '\n",
      "                   'Ballantine Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'The Vampire Lestat (Vampire Chronicles, Book II)'},\n",
      "  0.9983704),\n",
      " ({'id': '0380730138',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0380730138.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': \"Vinegar Hill (Oprah's Book Club (Paperback)) A. Manette \"\n",
      "                   'Ansay Perennial',\n",
      "   'product_tags': nan,\n",
      "   'product_title': \"Vinegar Hill (Oprah's Book Club (Paperback))\"},\n",
      "  0.9983375),\n",
      " ({'id': '0060191929',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0060191929.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'The Saving Graces : A Novel Patricia Gaffney HarperCollins',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'The Saving Graces : A Novel'},\n",
      "  0.9982761),\n",
      " ({'id': '0553272837',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0553272837.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Brazen Virtue Nora Roberts Bantam Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Brazen Virtue'},\n",
      "  0.9981637)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TitleWordVecTitleyRecommender(RecommendationAbstract):\n",
    "    \n",
    "    strategy_name: str = \"TitleWordVec\"\n",
    "    slug_name: str = \"title_word_vec\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data):\n",
    "        \"\"\"\n",
    "        Initialize the recommender with a pre-trained Word2Vec model and a dataframe of books.\n",
    "        \"\"\"\n",
    "        super().__init__(products, product_data)\n",
    "        self.products_df = products\n",
    "        self.model = None\n",
    "        self.train()\n",
    "\n",
    "    def train(self, auto_save=False):\n",
    "        \"\"\"\n",
    "        Train the Word2Vec model on the book titles.\n",
    "        \"\"\"\n",
    "        sentences = [title.lower().split() for title in self.products_df['product_title']]\n",
    "        self.model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "        if auto_save:\n",
    "            self.save()\n",
    "\n",
    "    def recommend_from_single(self, product_id, n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        # Get the product_title for the given product_id\n",
    "        product_title = self.products_df.loc[self.products_df['id'] == product_id, 'product_title'].values[0]\n",
    "        # Use the recommend_books_updated function to recommend books based on the product_title\n",
    "        recommendations = self.recommend_books_updated(product_title, top_n=n)\n",
    "        return recommendations\n",
    "    \n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        \"\"\"\n",
    "        Return recommendations based on past transactions.\n",
    "        \"\"\"\n",
    "        # Concatenate product_titles from past transactions\n",
    "        past_titles = self.products_df.loc[self.products_df['id'].isin(transactions), 'product_title']\n",
    "        # Use the self.recommend_books_updated function to recommend books based on past transactions\n",
    "        recommendations = self.recommend_books_updated(' '.join(past_titles), top_n=n)\n",
    "        return recommendations\n",
    "\n",
    "        \n",
    "\n",
    "    def recommend_books_updated(self, input_text, top_n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on input text.\n",
    "        \"\"\"\n",
    "        input_text = input_text.lower().split()\n",
    "        vector = self.model.wv[input_text].mean(axis=0)\n",
    "        # Compute cosine similarity between the input vector and all product vectors\n",
    "        similarities = cosine_similarity([vector], self.model.wv.vectors)\n",
    "        # Get indices of top similar products\n",
    "        top_indices = similarities.argsort()[0][-top_n:]\n",
    "        recommended_products = []\n",
    "        for index in reversed(top_indices):  # Reversed to get top similarities first\n",
    "            product_title = self.products_df.iloc[index]['product_title']\n",
    "            confidence = similarities[0][index]\n",
    "            recommended_products.append((self.id_to_productDetail(self.products_df.iloc[index]['id']), confidence))\n",
    "        return recommended_products\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save the computed book vectors to a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        with open(filename, 'wb') as filemodel:\n",
    "            pickle.dump(self.model, filemodel)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load the book vectors from a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        with open(filename, 'rb') as filemodel:\n",
    "            self.model = pickle.load(filemodel)\n",
    "\n",
    "    def get_filename(self):\n",
    "        \"\"\"\n",
    "        Get the filename for saving/loading the model.\n",
    "        \"\"\"\n",
    "        return \"models/\" + self.slug_name + self.product_data[\"unique_name\"] + \".model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random and recommend.\n",
    "wordvecRecommender = TitleWordVecTitleyRecommender(productdf, product_data)\n",
    "# Train.\n",
    "# wordvecRecommender.train( auto_save=True)\n",
    "wordvecRecommender.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0373872062',\n",
      " 'product_image': 'http://images.amazon.com/images/P/0373872062.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': 'Loving Hearts Gail Gaymer Martin Steeple Hill',\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'Loving Hearts'}\n",
      "=============  RECOMENDATIONS  ============\n",
      "[({'id': '0452264464',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0452264464.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Beloved (Plume Contemporary Fiction) Toni Morrison Plume',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Beloved (Plume Contemporary Fiction)'},\n",
      "  0.99993634),\n",
      " ({'id': '0002005018',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0002005018.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Clara Callan Richard Bruce Wright HarperFlamingo Canada',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Clara Callan'},\n",
      "  0.99988186),\n",
      " ({'id': '0345417623',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0345417623.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Timeline MICHAEL CRICHTON Ballantine Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Timeline'},\n",
      "  0.99985254),\n",
      " ({'id': '0425182908',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0425182908.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Isle of Dogs Patricia Cornwell Berkley Publishing Group',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Isle of Dogs'},\n",
      "  0.99983805),\n",
      " ({'id': '042518630X',\n",
      "   'product_image': 'http://images.amazon.com/images/P/042518630X.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Purity in Death J.D. Robb Berkley Publishing Group',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Purity in Death'},\n",
      "  0.99983525),\n",
      " ({'id': '0399135782',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0399135782.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': \"The Kitchen God's Wife Amy Tan Putnam Pub Group\",\n",
      "   'product_tags': nan,\n",
      "   'product_title': \"The Kitchen God's Wife\"},\n",
      "  0.9998309),\n",
      " ({'id': '0061099686',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0061099686.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Downtown Anne Rivers Siddons HarperTorch',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Downtown'},\n",
      "  0.99981725),\n",
      " ({'id': '1841721522',\n",
      "   'product_image': 'http://images.amazon.com/images/P/1841721522.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'New Vegetarian: Bold and Beautiful Recipes for Every '\n",
      "                   'Occasion Celia Brooks Brown Ryland Peters &amp; Small Ltd',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'New Vegetarian: Bold and Beautiful Recipes for Every '\n",
      "                    'Occasion'},\n",
      "  0.9998129),\n",
      " ({'id': '0394895894',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0394895894.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'The Ruby in the Smoke (Sally Lockhart Trilogy, Book 1) '\n",
      "                   'PHILIP PULLMAN Laurel Leaf',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'The Ruby in the Smoke (Sally Lockhart Trilogy, Book 1)'},\n",
      "  0.9997958),\n",
      " ({'id': '1853260053',\n",
      "   'product_image': 'http://images.amazon.com/images/P/1853260053.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': \"Tess of the D'Urbervilles (Wordsworth Classics) Thomas \"\n",
      "                   'Hardy NTC/Contemporary Publishing Company',\n",
      "   'product_tags': nan,\n",
      "   'product_title': \"Tess of the D'Urbervilles (Wordsworth Classics)\"},\n",
      "  0.9997867)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "randomProduct = wordvecRecommender.get_random_recommendation()[0]\n",
    "pprint.pprint(randomProduct)\n",
    "wordvecRecommender.recommend_from_single(randomProduct['id'])\n",
    "\n",
    "\n",
    "# ... Repetition.\n",
    "print(\"=============  RECOMENDATIONS  ============\")\n",
    "rec_id = wordvecRecommender.recommend_from_past(tansactions)\n",
    "pprint.pprint(rec_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============  RECOMENDATIONS RECOMMENDATIONS  ============\n",
      "[({'id': '0452264464',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0452264464.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Beloved (Plume Contemporary Fiction) Toni Morrison Plume',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Beloved (Plume Contemporary Fiction)'},\n",
      "  0.99993634),\n",
      " ({'id': '0002005018',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0002005018.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Clara Callan Richard Bruce Wright HarperFlamingo Canada',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Clara Callan'},\n",
      "  0.99988186),\n",
      " ({'id': '0345417623',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0345417623.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Timeline MICHAEL CRICHTON Ballantine Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Timeline'},\n",
      "  0.99985254),\n",
      " ({'id': '0425182908',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0425182908.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Isle of Dogs Patricia Cornwell Berkley Publishing Group',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Isle of Dogs'},\n",
      "  0.99983805),\n",
      " ({'id': '042518630X',\n",
      "   'product_image': 'http://images.amazon.com/images/P/042518630X.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Purity in Death J.D. Robb Berkley Publishing Group',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Purity in Death'},\n",
      "  0.99983525),\n",
      " ({'id': '0399135782',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0399135782.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': \"The Kitchen God's Wife Amy Tan Putnam Pub Group\",\n",
      "   'product_tags': nan,\n",
      "   'product_title': \"The Kitchen God's Wife\"},\n",
      "  0.9998309),\n",
      " ({'id': '0061099686',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0061099686.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Downtown Anne Rivers Siddons HarperTorch',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Downtown'},\n",
      "  0.99981725),\n",
      " ({'id': '1841721522',\n",
      "   'product_image': 'http://images.amazon.com/images/P/1841721522.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'New Vegetarian: Bold and Beautiful Recipes for Every '\n",
      "                   'Occasion Celia Brooks Brown Ryland Peters &amp; Small Ltd',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'New Vegetarian: Bold and Beautiful Recipes for Every '\n",
      "                    'Occasion'},\n",
      "  0.9998129),\n",
      " ({'id': '0394895894',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0394895894.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'The Ruby in the Smoke (Sally Lockhart Trilogy, Book 1) '\n",
      "                   'PHILIP PULLMAN Laurel Leaf',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'The Ruby in the Smoke (Sally Lockhart Trilogy, Book 1)'},\n",
      "  0.9997958),\n",
      " ({'id': '1853260053',\n",
      "   'product_image': 'http://images.amazon.com/images/P/1853260053.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': \"Tess of the D'Urbervilles (Wordsworth Classics) Thomas \"\n",
      "                   'Hardy NTC/Contemporary Publishing Company',\n",
      "   'product_tags': nan,\n",
      "   'product_title': \"Tess of the D'Urbervilles (Wordsworth Classics)\"},\n",
      "  0.9997867)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ... Repetition.\n",
    "print(\"=============  RECOMENDATIONS RECOMMENDATIONS  ============\")\n",
    "tansactions = ['0590353403', '0439139597']\n",
    "\n",
    "\"\"\"\n",
    "Harry Potter and the Sorcerer's Stone (Book 1)\n",
    "\"Harry Potter and the Goblet of Fire (Book 4)\"\n",
    "\"\"\"\n",
    "\n",
    "rec_id = wordvecRecommender.recommend_from_past(tansactions)\n",
    "pprint.pprint(rec_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TitleWordVecTitleyRecommenderV2(RecommendationAbstract):\n",
    "    \"\"\"\n",
    "    Key Changes:\n",
    "    - Using nlp to search first nouns>verbs>adjectives\n",
    "    - Past Transactions search instead of the aggregated titles, makes individual search with prioritization with eah title\n",
    "    \"\"\"\n",
    "    strategy_name: str = \"TitleWordVec\"\n",
    "    slug_name: str = \"title_word_vec\"\n",
    "    version: str = \"v2\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data, useKeyword=True):\n",
    "        \"\"\"\n",
    "        Initialize the recommender with a pre-trained Word2Vec model and a dataframe of books.\n",
    "        \"\"\"\n",
    "        super().__init__(products, product_data)\n",
    "        self.products_df = products\n",
    "        self.model = None\n",
    "        self.train()\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.useKeyword = useKeyword # Otherwise uses the list of keywords concatenated found.\n",
    "\n",
    "    def train(self, auto_save=False):\n",
    "        \"\"\"\n",
    "        Train the Word2Vec model on the book titles.\n",
    "        \"\"\"\n",
    "        # Preprocess text data\n",
    "        self.products_df['processed_soup'] = self.products_df['product_title'].str.lower().str.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        # Prepare self.products_df for Word2Vec model\n",
    "        sentences = [row.split() for row in self.products_df['processed_soup'].dropna()]\n",
    "        self.model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "        if auto_save:\n",
    "            self.save()\n",
    "\n",
    "\n",
    "    def getMostSignificantKeyword(self, text, default_to_text = True, k=3) -> tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Extracts keywords from the provided text, prioritizing nouns, then verbs, then adjectives.\n",
    "        Continues until the combined length of keywords is at least 3 characters.\n",
    "        \n",
    "        This algorithm is designed to work for short range titles.\n",
    "        - default_to_\n",
    "        \n",
    "        Returns a tuple of (most_relevant_keyword, an_concatenated_list_of_keywords)\n",
    "        \"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        priorityKey = \"\"\n",
    "        top_keywords = []\n",
    "        fullsearch = \"\"\n",
    "\n",
    "        # Define the order of part of speech tags to search based on their relevance\n",
    "        pos_priority = [\"NOUN\", \"VERB\", \"ADJ\", \"PROPN\", \"ADV\", \"PRON\", \"ADP\", \"CCONJ\", \"SCONJ\", \"DET\", \"AUX\", \"NUM\",\n",
    "                        \"PART\", \"INTJ\", \"SYM\", \"PUNCT\", \"X\"]\n",
    "\n",
    "        # Iterate over each part of speech in priority order\n",
    "        for pos in pos_priority:\n",
    "            keywords = [token.text for token in doc if token.pos_ == pos]\n",
    "            for key in keywords:\n",
    "                fullsearch += f\" {key}\"  # Append all found keywords to fullsearch\n",
    "                if len(key) > len(priorityKey):\n",
    "                    priorityKey = key  # Update priorityKey if a longer keyword is found\n",
    "                if len(top_keywords) < k:\n",
    "                    top_keywords.append(key)  # Add the keyword to top_keywords if there are less than k\n",
    "                if len(priorityKey) >= k and len(top_keywords) == k:\n",
    "                    break  # Break both loops if condition is met\n",
    "            if len(priorityKey) >= k and len(top_keywords) == k:\n",
    "                break  # Break outer loop if condition is met\n",
    "        # If there are more than k words, and not enough top words, to fulfill k. Add as many words as possible to get to k.\n",
    "        if len(top_keywords) < k:\n",
    "            set_keywords = set(top_keywords)\n",
    "            for word in text.split():\n",
    "                if word not in set_keywords:\n",
    "                    set_keywords.add(word)\n",
    "                if len(top_keywords) == k:\n",
    "                    break\n",
    "            set_keywords = list(set_keywords)\n",
    "        \n",
    "        # print(priorityKey, ' '.join(top_keywords), fullsearch)\n",
    "        return (' '.join(top_keywords), fullsearch)\n",
    "        \n",
    "\n",
    "    def recommend_from_single(self, product_id, n=5, verbose=True, greedy_attempt=3) -> List[tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        # Get the product_title for the given product_id\n",
    "        product_title = self.products_df.loc[self.products_df['id'] == product_id, 'product_title'].values[0]\n",
    "        # Use the recommend_books_updated function to recommend books based on the product_title\n",
    "        recommendations = []\n",
    "        search_term = \"\"\n",
    "        seen = set(product_title)\n",
    "        for k in range(greedy_attempt):\n",
    "            keyword, keywords_concat = self.getMostSignificantKeyword(product_title, k=k+1)\n",
    "            if(self.useKeyword):\n",
    "                search_term = keyword\n",
    "            else:\n",
    "                search_term = keywords_concat\n",
    "            if verbose:\n",
    "                print(f\"Searching for '{search_term}' from '{product_title}'\")\n",
    "                # print(recommendations)\n",
    "        \n",
    "            rec = self.recommend_books_updated(search_term, top_n=n)\n",
    "            for rec_item, confidence_rate in rec:\n",
    "                # print(rec_item)\n",
    "                if rec_item['product_title'] not in seen:\n",
    "                    seen.add(rec_item['product_title'])\n",
    "                    recommendations.append((rec_item, confidence_rate))\n",
    "                else:\n",
    "                    continue\n",
    "            if len(recommendations) >= greedy_attempt:\n",
    "                break\n",
    "        return recommendations\n",
    "    \n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        \"\"\"\n",
    "        Return recommendations based on past transactions.\n",
    "        Does the following:\n",
    "        \n",
    "        @param transactions: List[id] = List of transactions\n",
    "        \n",
    "        - Per each transaction uses recommend_from_single, to find relevant books. around 5 recommendations.\n",
    "        - ensures that the recommendations are unique.\n",
    "        - Sorts by confidence.\n",
    "        - limits to n.\n",
    "        \"\"\"\n",
    "    \n",
    "        for transaction in transactions:\n",
    "            rec: List[tuple[dict, int]] = self.recommend_from_single(transaction)\n",
    "            rec.extend(rec) \n",
    "        # Because there could be repeated rec[i]['product_title'] we need to remove duplicates.\n",
    "        seen_titles = set()\n",
    "        unique_rec = []\n",
    "        for rec_item, confidence_rate in rec:\n",
    "            if rec_item['product_title'] not in seen_titles:\n",
    "                seen_titles.add(rec_item['product_title'])\n",
    "                unique_rec.append((rec_item, confidence_rate))\n",
    "                    \n",
    "        \n",
    "        # Sort by confidence second parameter\n",
    "        unique_rec.sort(key=lambda x: x[1])\n",
    "        return unique_rec[:n]\n",
    "        \n",
    "\n",
    "    def recommend_books_updated(self, input_text, top_n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on input text.\n",
    "        \"\"\"\n",
    "        input_text = input_text.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "        vector = self.model.wv[input_text].mean(axis=0)\n",
    "        similar_vectors = self.model.wv.similar_by_vector(vector, topn=top_n + 10)  # Retrieve more results to filter unique titles\n",
    "        recommended_titles = []\n",
    "        for book_vector in similar_vectors:\n",
    "            similar_title = self.products_df.loc[self.products_df['processed_soup'].apply(lambda x: any(word in x for word in input_text)), 'processed_soup'].unique()\n",
    "            for title in similar_title:\n",
    "                if title not in recommended_titles and len(recommended_titles) < top_n:\n",
    "                    product = self.products_df.loc[self.products_df['processed_soup'] == title].iloc[0].to_dict()\n",
    "                    recommended_titles.append((product, book_vector[1]))\n",
    "        return recommended_titles\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save the computed book vectors to a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        with open(filename, 'wb') as filemodel:\n",
    "            pickle.dump(self.model, filemodel)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load the book vectors from a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        with open(filename, 'rb') as filemodel:\n",
    "            self.model = pickle.load(filemodel)\n",
    "\n",
    "    def get_filename(self):\n",
    "        \"\"\"\n",
    "        Get the filename for saving/loading the model.\n",
    "        \"\"\"\n",
    "        return \"models/\" + self.slug_name + self.product_data[\"unique_name\"] + \".model\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '../data/products_books_v1_10_10.csv'\n",
    "# data = pd.read_csv(file_path)\n",
    "# print(len(data))\n",
    "# engineRec = TitleWordVecTitleyRecommenderV2(data, product_data)\n",
    "engineRec = TitleWordVecTitleyRecommenderV2(productdf, product_data)\n",
    "engineRec.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0553565370',\n",
      " 'processed_soup': 'scandal in fair haven',\n",
      " 'product_image': 'http://images.amazon.com/images/P/0553565370.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': 'Scandal in Fair Haven Carolyn G. Hart Bantam Books',\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'Scandal in Fair Haven'}\n",
      "======== RECOMENDATIONS SINGLE CASE =========== \n",
      "Searching for 'Scandal' from 'Scandal in Fair Haven'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'id': '0060505885',\n",
       "   'product_title': 'The Scandalous Summer of Sissy LeBlanc : A Novel',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0060505885.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'The Scandalous Summer of Sissy LeBlanc : A Novel Loraine Despres Perennial',\n",
       "   'product_tags': nan,\n",
       "   'processed_soup': 'the scandalous summer of sissy leblanc  a novel'},\n",
       "  0.9999999403953552),\n",
       " ({'id': '038078615X',\n",
       "   'product_title': \"Married at Midnight an Anthology: The Determined Bride/A Kiss After Midnight/Scandal's Bride/Beyond the Kiss\",\n",
       "   'product_image': 'http://images.amazon.com/images/P/038078615X.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': \"Married at Midnight an Anthology: The Determined Bride/A Kiss After Midnight/Scandal's Bride/Beyond the Kiss Kathleen E. Woodiwiss Avon\",\n",
       "   'product_tags': nan,\n",
       "   'processed_soup': 'married at midnight an anthology the determined bridea kiss after midnightscandals bridebeyond the kiss'},\n",
       "  0.9999999403953552),\n",
       " ({'id': '0515114006',\n",
       "   'product_title': 'Private Scandals',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0515114006.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Private Scandals Nora Roberts Jove Books',\n",
       "   'product_tags': nan,\n",
       "   'processed_soup': 'private scandals'},\n",
       "  0.9999999403953552),\n",
       " ({'id': '0373835795',\n",
       "   'product_title': 'Simply Scandalous (Simply (Harlequin))',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0373835795.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Simply Scandalous (Simply (Harlequin)) Carly Phillips Harlequin',\n",
       "   'product_tags': nan,\n",
       "   'processed_soup': 'simply scandalous simply harlequin'},\n",
       "  0.9999999403953552),\n",
       " ({'id': '0380805685',\n",
       "   'product_title': \"Scandal's Bride (Cynster Novels)\",\n",
       "   'product_image': 'http://images.amazon.com/images/P/0380805685.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': \"Scandal's Bride (Cynster Novels) Stephanie Laurens Avon\",\n",
       "   'product_tags': nan,\n",
       "   'processed_soup': 'scandals bride cynster novels'},\n",
       "  0.9999999403953552)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "randomProduct = engineRec.get_random_recommendation()[0]\n",
    "pprint.pprint(randomProduct)\n",
    "\n",
    "print('======== RECOMENDATIONS SINGLE CASE =========== ')\n",
    "engineRec.recommend_from_single(randomProduct['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============  RECOMENDATIONS RECOMMENDATIONS  ============\n",
      "Searching for 'Harry' from 'Harry Potter and the Sorcerer's Stone (Book 1)'\n",
      "Searching for 'Harry' from 'Harry Potter and the Goblet of Fire (Book 4)'\n",
      "[({'id': '0767908473',\n",
      "   'processed_soup': 'the sorcerers companion a guide to the magical world of '\n",
      "                     'harry potter',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0767908473.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': \"The Sorcerer's Companion: A Guide to the Magical World of \"\n",
      "                   'Harry Potter ALLAN ZOLA KRONZEK Broadway',\n",
      "   'product_tags': nan,\n",
      "   'product_title': \"The Sorcerer's Companion: A Guide to the Magical World of \"\n",
      "                    'Harry Potter'},\n",
      "  0.9999998807907104),\n",
      " ({'id': '059035342X',\n",
      "   'processed_soup': 'harry potter and the sorcerers stone harry potter '\n",
      "                     'paperback',\n",
      "   'product_image': 'http://images.amazon.com/images/P/059035342X.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': \"Harry Potter and the Sorcerer's Stone (Harry Potter \"\n",
      "                   '(Paperback)) J. K. Rowling Arthur A. Levine Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': \"Harry Potter and the Sorcerer's Stone (Harry Potter \"\n",
      "                    '(Paperback))'},\n",
      "  0.9999998807907104),\n",
      " ({'id': '0590353403',\n",
      "   'processed_soup': 'harry potter and the sorcerers stone book 1',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0590353403.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': \"Harry Potter and the Sorcerer's Stone (Book 1) J. K. \"\n",
      "                   'Rowling Scholastic',\n",
      "   'product_tags': nan,\n",
      "   'product_title': \"Harry Potter and the Sorcerer's Stone (Book 1)\"},\n",
      "  0.9999998807907104),\n",
      " ({'id': '0439064872',\n",
      "   'processed_soup': 'harry potter and the chamber of secrets book 2',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0439064872.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Harry Potter and the Chamber of Secrets (Book 2) J. K. '\n",
      "                   'Rowling Scholastic',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Harry Potter and the Chamber of Secrets (Book 2)'},\n",
      "  0.9999998807907104),\n",
      " ({'id': '0439136350',\n",
      "   'processed_soup': 'harry potter and the prisoner of azkaban book 3',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0439136350.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Harry Potter and the Prisoner of Azkaban (Book 3) J. K. '\n",
      "                   'Rowling Scholastic',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Harry Potter and the Prisoner of Azkaban (Book 3)'},\n",
      "  0.9999998807907104)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ... Repetition.\n",
    "print(\"=============  RECOMENDATIONS RECOMMENDATIONS  ============\")\n",
    "tansactions = ['0590353403', '0439139597']\n",
    "\n",
    "\"\"\"\n",
    "Harry Potter and the Sorcerer's Stone (Book 1)\n",
    "\"Harry Potter and the Goblet of Fire (Book 4)\"\n",
    "\"\"\"\n",
    "\n",
    "rec_id = engineRec.recommend_from_past(tansactions)\n",
    "pprint.pprint(rec_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineRec.recommend_books_updated(\"Harry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the class using cosine Similarity.\n",
    "from surprise import KNNBasic\n",
    "\n",
    "class BasicKNNRecommender(RecommendationAbstract):\n",
    "    strategy_name: str = \"Basic KNN\"\n",
    "    slug_name: str = \"basic_knn\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products: pd.DataFrame, product_data: dict):\n",
    "        super().__init__(products, product_data)\n",
    "        self.products = products\n",
    "        self.model = None\n",
    "        \n",
    "        # Get the product ids and store them.\n",
    "        self.product_ids = self.products['id'].unique()\n",
    "        \n",
    "    def train(self, transactions, auto_save=True):\n",
    "        \n",
    "        sim_options = {\"name\": \"pearson_baseline\", \"user_based\": False}\n",
    "        model = KNNBasic(sim_options=sim_options)\n",
    "        \n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        \n",
    "        data = Dataset.load_from_df(transactions[['user_id', 'product_id', 'rate']], reader)\n",
    "        \n",
    "        model.fit(data.build_full_trainset())\n",
    "        self.model = model\n",
    "        # self.accuracy = accuracy.rmse(model.test(data.build_full_trainset().build_testset()), verbose=True)\n",
    "        \n",
    "        if auto_save:\n",
    "            self.save()\n",
    "        \n",
    "        \n",
    "    def get_filename(self):\n",
    "        return \"models/\" + self.slug_name + self.product_data[\"unique_name\"] + \".pik\"\n",
    "    \n",
    "    def save(self):\n",
    "        # Store self.pt\n",
    "        filename = self.get_filename()\n",
    "        model_file = open(filename, 'wb')\n",
    "        pickle.dump(self.model, model_file)\n",
    "        model_file.close()\n",
    "        \n",
    "    def load(self):\n",
    "        filename = self.get_filename()\n",
    "        model_file = open(filename, 'rb')\n",
    "        self.model = pickle.load(model_file)\n",
    "        model_file.close()\n",
    "        \n",
    "\n",
    "    def recommend_from_single(self, product_id: str, n=5) -> List[Tuple[dict, float]]:\n",
    "        \"\"\"\n",
    "        \n",
    "        # Retrieve inner ids of the nearest neighbors of Toy Story.\n",
    "        toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=10)\n",
    "        \"\"\"\n",
    "        recommendation_list: List[tuple[dict, float]] = []\n",
    "        \n",
    "        product_inner_id = self.model.trainset.to_inner_iid(product_id)\n",
    "        \n",
    "        neighbors = self.model.get_neighbors(product_inner_id, k=n)\n",
    "        \n",
    "        for neighbor in neighbors:\n",
    "            product_serie = self.products.iloc[neighbor]\n",
    "            product = product_serie.to_dict()\n",
    "            recommendation_list.append((product, 1.0))\n",
    "        \n",
    "        return recommendation_list[:n]\n",
    "\n",
    "\n",
    "    def recommend_from_past(self, transactions: List[str], n=10):\n",
    "        \"\"\"\n",
    "        Calls for each transaction the recommend_from_single method.\n",
    "        Gives Priority if seen multiple recommendations.\n",
    "        Shuffle and returns :n\n",
    "        \"\"\"\n",
    "        recs = set()\n",
    "        recs_seen_times = {}\n",
    "        products_dictionary = {}\n",
    "        \n",
    "        for transaction in transactions:\n",
    "            recs = self.recommend_from_single(transaction)\n",
    "            for rec_id, confidence in recs:\n",
    "                \n",
    "                if rec_id in recs:\n",
    "                    recs_seen_times[rec_id['id']] += 1\n",
    "                else:\n",
    "                    products_dictionary[rec_id['id']] = rec_id\n",
    "                    recs_seen_times[rec_id['id']] = 1\n",
    "        \n",
    "        for rec_id in recs_seen_times:\n",
    "            recs.append((products_dictionary[rec_id], recs_seen_times[rec_id]))\n",
    "            \n",
    "        recs = list(recs)\n",
    "        # sort\n",
    "        \n",
    "        recs.sort(key=lambda x: x[1], reverse=True)\n",
    "        return recs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engineRec = BasicKNNRecommender(productdf, product_data)\n",
    "# engineRec.train(transactions=transactiondf, auto_save=True)\n",
    "engineRec.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 19,\n",
      " 'id': '0380818337',\n",
      " 'product_id': '0380818337',\n",
      " 'product_image': 'http://images.amazon.com/images/P/0380818337.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': 'The Lady Is Tempted Cathy Maxwell Avon',\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'The Lady Is Tempted'}\n",
      "======== RECOMENDATIONS SINGLE CASE =========== \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'product_id': '0307010856',\n",
       "   'count': 10,\n",
       "   'id': '0307010856',\n",
       "   'product_title': 'The Monster at the End of This Book',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0307010856.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'The Monster at the End of This Book JON STONE Golden Books',\n",
       "   'product_tags': nan},\n",
       "  1.0),\n",
       " ({'product_id': '0553582364',\n",
       "   'count': 50,\n",
       "   'id': '0553582364',\n",
       "   'product_title': 'A Traitor to Memory',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0553582364.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'A Traitor to Memory Elizabeth George Bantam Books',\n",
       "   'product_tags': nan},\n",
       "  1.0),\n",
       " ({'product_id': '0425114236',\n",
       "   'count': 51,\n",
       "   'id': '0425114236',\n",
       "   'product_title': 'Accidental Tourist',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0425114236.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Accidental Tourist Anne Tyler Penguin Putnam~mass',\n",
       "   'product_tags': nan},\n",
       "  1.0),\n",
       " ({'product_id': '0451151259',\n",
       "   'count': 72,\n",
       "   'id': '0451151259',\n",
       "   'product_title': 'Eyes of the Dragon',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0451151259.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Eyes of the Dragon Stephen King Penguin Putnam~mass',\n",
       "   'product_tags': nan},\n",
       "  1.0),\n",
       " ({'product_id': '0452274664',\n",
       "   'count': 11,\n",
       "   'id': '0452274664',\n",
       "   'product_title': 'The Autobiography of My Mother',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0452274664.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'The Autobiography of My Mother Jamaica Kincaid Plume Books',\n",
       "   'product_tags': nan},\n",
       "  1.0)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "randomProduct = engineRec.get_random_recommendation()[0]\n",
    "\n",
    "pprint.pprint(randomProduct)\n",
    "\n",
    "  \n",
    "\n",
    "print('======== RECOMENDATIONS SINGLE CASE =========== ')\n",
    "\n",
    "engineRec.recommend_from_single(randomProduct['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= RECOMENDATIONS RECOMMENDATIONS ============\n",
      "[({'count': 40,\n",
      "   'id': '0786884142',\n",
      "   'product_id': '0786884142',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0786884142.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'A Monk Swimming : A Memoir Malachy McCourt Hyperion',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'A Monk Swimming : A Memoir'},\n",
      "  1.0),\n",
      " ({'count': 266,\n",
      "   'id': '0446606812',\n",
      "   'product_id': '0446606812',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0446606812.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Message in a Bottle Nicholas Sparks Warner Vision',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Message in a Bottle'},\n",
      "  1.0),\n",
      " ({'count': 58,\n",
      "   'id': '0061091790',\n",
      "   'product_id': '0061091790',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0061091790.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'After All These Years Susan Isaacs HarperTorch',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'After All These Years'},\n",
      "  1.0),\n",
      " ({'count': 39,\n",
      "   'id': '0385323638',\n",
      "   'product_id': '0385323638',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0385323638.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Pink Slip RITA CIRESI Delta',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Pink Slip'},\n",
      "  1.0),\n",
      " ({'count': 238,\n",
      "   'id': '0316096199',\n",
      "   'product_id': '0316096199',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0316096199.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Lucky : A Memoir Alice Sebold Back Bay Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Lucky : A Memoir'},\n",
      "  1.0),\n",
      " ({'count': 40,\n",
      "   'id': '0786884142',\n",
      "   'product_id': '0786884142',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0786884142.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'A Monk Swimming : A Memoir Malachy McCourt Hyperion',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'A Monk Swimming : A Memoir'},\n",
      "  1),\n",
      " ({'count': 266,\n",
      "   'id': '0446606812',\n",
      "   'product_id': '0446606812',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0446606812.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Message in a Bottle Nicholas Sparks Warner Vision',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Message in a Bottle'},\n",
      "  1),\n",
      " ({'count': 40,\n",
      "   'id': '0140053204',\n",
      "   'product_id': '0140053204',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0140053204.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Travels With Charley: In Search of America John Steinbeck '\n",
      "                   'Penguin Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Travels With Charley: In Search of America'},\n",
      "  1),\n",
      " ({'count': 58,\n",
      "   'id': '0061091790',\n",
      "   'product_id': '0061091790',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0061091790.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'After All These Years Susan Isaacs HarperTorch',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'After All These Years'},\n",
      "  1),\n",
      " ({'count': 58,\n",
      "   'id': '0671776134',\n",
      "   'product_id': '0671776134',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0671776134.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Plain Truth Jodi Picoult Washington Square Press',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Plain Truth'},\n",
      "  1),\n",
      " ({'count': 39,\n",
      "   'id': '0385323638',\n",
      "   'product_id': '0385323638',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0385323638.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Pink Slip RITA CIRESI Delta',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Pink Slip'},\n",
      "  1),\n",
      " ({'count': 238,\n",
      "   'id': '0316096199',\n",
      "   'product_id': '0316096199',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0316096199.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Lucky : A Memoir Alice Sebold Back Bay Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Lucky : A Memoir'},\n",
      "  1)]\n"
     ]
    }
   ],
   "source": [
    "print(\"============= RECOMENDATIONS RECOMMENDATIONS ============\")\n",
    "\n",
    "tansactions = ['0590353403', '0439139597']\n",
    "\n",
    "\n",
    "rec_id = engineRec.recommend_from_past(tansactions)\n",
    "\n",
    "pprint.pprint(rec_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from surprise import KNNWithMeans\n",
    "\n",
    "class KNNWithMeansRecommender(RecommendationAbstract):\n",
    "    strategy_name: str = \"KNN With Means\"\n",
    "    slug_name: str = \"knn_with_means\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products: pd.DataFrame, product_data: dict):\n",
    "        super().__init__(products, product_data)\n",
    "        self.products = products\n",
    "        self.model = None\n",
    "        \n",
    "        # Get the product ids and store them.\n",
    "        self.product_ids = self.products['id'].unique()\n",
    "        self.all_transactions_df = None\n",
    "        \n",
    "    def train(self, transactions, auto_save=True, dont_save_self_state=False) :\n",
    "        \n",
    "        sim_options = {\"name\": \"pearson_baseline\", \"user_based\": False}\n",
    "        model = KNNWithMeans(sim_options=sim_options)\n",
    "        \n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        \n",
    "        data = Dataset.load_from_df(transactions[['user_id', 'product_id', 'rate']], reader)\n",
    "        \n",
    "        model.fit(data.build_full_trainset())\n",
    "        \n",
    "        if dont_save_self_state:\n",
    "            return model\n",
    "        \n",
    "        self.model = model\n",
    "        self.all_transactions_df = transactions\n",
    "        # self.accuracy = accuracy.rmse(model.test(data.build_full_trainset().build_testset()), verbose=True)\n",
    "        \n",
    "        if auto_save:\n",
    "            self.save()\n",
    "            \n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def get_filename(self):\n",
    "        return \"models/\" + self.slug_name + self.product_data[\"unique_name\"] + \".pik\"\n",
    "    \n",
    "    def save(self):\n",
    "        # Store self.pt\n",
    "        filename = self.get_filename()\n",
    "        model_file = open(filename, 'wb')\n",
    "        pickle.dump(self.model, model_file)\n",
    "        model_file.close()\n",
    "        \n",
    "    def load(self):\n",
    "        filename = self.get_filename()\n",
    "        model_file = open(filename, 'rb')\n",
    "        self.model = pickle.load(model_file)\n",
    "        model_file.close()\n",
    "        \n",
    "\n",
    "    def recommend_from_single(self, product_id: str, n=5) -> List[Tuple[dict, float]]:\n",
    "        \"\"\"\n",
    "        \n",
    "        # Retrieve inner ids of the nearest neighbors of Toy Story.\n",
    "        toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=10)\n",
    "        \"\"\"\n",
    "        recommendation_list: List[tuple[dict, float]] = []\n",
    "        \n",
    "        product_inner_id = self.model.trainset.to_inner_iid(product_id)\n",
    "        \n",
    "        neighbors = self.model.get_neighbors(product_inner_id, k=n)\n",
    "        \n",
    "        for neighbor in neighbors:\n",
    "            product_serie = self.products.iloc[neighbor]\n",
    "            product = product_serie.to_dict()\n",
    "            recommendation_list.append((product, 1.0))\n",
    "        \n",
    "        return recommendation_list[:n]\n",
    "\n",
    "    def collaborativestore_predict_population(self, transactions: List[str], n=5):\n",
    "        \"\"\"\n",
    "        Adds the transactions to the use history\n",
    "        'user_id', 'product_id', 'rate'\n",
    "        \"\"\"\n",
    "        # Add transactions to the self.transactions_df as a new user\n",
    "        transaction_rows = []\n",
    "        random_user_id = \"user\" + str(random.randint(0, 1000000))\n",
    "        for transaction in transactions:\n",
    "            transaction_rows.append({'user_id': 'user_id', 'product_id': transaction, 'rate': 5})\n",
    "        \n",
    "        # Convert to a DataFrame\n",
    "        new_transactions_df = pd.DataFrame(transaction_rows)\n",
    "\n",
    "        # Append using concat\n",
    "        all_transactions_df: pd.Dataframe = pd.concat([self.all_transactions_df, new_transactions_df], ignore_index=True)\n",
    "        \n",
    "        model = self.train(all_transactions_df, dont_save_self_state=True)\n",
    "        \n",
    "        return self.predict_recommendations(random_user_id, transactions, model, n)\n",
    "    \n",
    "    def predict_recommendations(self, user_id: str, transactions: List[str], model, n=5):\n",
    "        books_to_predict = [book_id for book_id in self.product_ids if book_id not in transactions]\n",
    "        predictions = []\n",
    "        \n",
    "        for book_id in books_to_predict:\n",
    "            pred = model.predict(user_id, book_id)\n",
    "            predictions.append((book_id, pred.est))\n",
    "        \n",
    "        pred_products = []\n",
    "        # sort predictions\n",
    "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "        for book_id, confidence in predictions[:n]:\n",
    "            product = self.id_to_products[book_id]\n",
    "            pred_products.append(product)\n",
    "            \n",
    "        return pred_products\n",
    "        \n",
    "\n",
    "    def recommend_from_past(self, transactions: List[str], n=10):\n",
    "        \"\"\"\n",
    "        Calls for each transaction the recommend_from_single method.\n",
    "        Gives Priority if seen multiple recommendations.\n",
    "        Shuffle and returns :n\n",
    "        \"\"\"\n",
    "        recs = set()\n",
    "        recs_seen_times = {}\n",
    "        products_dictionary = {}\n",
    "        \n",
    "        return self.collaborativestore_predict_population(\n",
    "            transactions, n=n\n",
    "        )\n",
    "        \n",
    "        for transaction in transactions:\n",
    "            recs = self.recommend_from_single(transaction)\n",
    "            for rec_id, confidence in recs:\n",
    "                \n",
    "                if rec_id in recs:\n",
    "                    recs_seen_times[rec_id['id']] += 1\n",
    "                else:\n",
    "                    products_dictionary[rec_id['id']] = rec_id\n",
    "                    recs_seen_times[rec_id['id']] = 1\n",
    "        \n",
    "        for rec_id in recs_seen_times:\n",
    "            recs.append((products_dictionary[rec_id], recs_seen_times[rec_id]))\n",
    "            \n",
    "        recs = list(recs)\n",
    "        # sort\n",
    "        \n",
    "        recs.sort(key=lambda x: x[1], reverse=True)\n",
    "        return recs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "{'count': 12,\n",
      " 'id': '0451456726',\n",
      " 'product_id': '0451456726',\n",
      " 'product_image': 'http://images.amazon.com/images/P/0451456726.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': 'Heir to the Shadows (The Black Jewels Trilogy, Book 2) Anne '\n",
      "                 'Bishop Roc',\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'Heir to the Shadows (The Black Jewels Trilogy, Book 2)'}\n",
      "======== RECOMENDATIONS SINGLE CASE =========== \n",
      "[({'count': 16,\n",
      "   'id': '0312194390',\n",
      "   'product_id': '0312194390',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0312194390.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'The Autobiography of Henry VIII: With Notes by His Fool, '\n",
      "                   \"Will Somers : A Novel Margaret George St. Martin's Press\",\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'The Autobiography of Henry VIII: With Notes by His Fool, '\n",
      "                    'Will Somers : A Novel'},\n",
      "  1.0),\n",
      " ({'count': 42,\n",
      "   'id': '1551669234',\n",
      "   'product_id': '1551669234',\n",
      "   'product_image': 'http://images.amazon.com/images/P/1551669234.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Stonebrook Cottage Carla Neggers Mira',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Stonebrook Cottage'},\n",
      "  1.0),\n",
      " ({'count': 14,\n",
      "   'id': '0312319142',\n",
      "   'product_id': '0312319142',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0312319142.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': \"Paranoia : A Novel Joseph Finder St. Martin's Press\",\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Paranoia : A Novel'},\n",
      "  1.0),\n",
      " ({'count': 105,\n",
      "   'id': '0441003257',\n",
      "   'product_id': '0441003257',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0441003257.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'Good Omens Neil Gaiman Ace Books',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'Good Omens'},\n",
      "  1.0),\n",
      " ({'count': 30,\n",
      "   'id': '0553210114',\n",
      "   'product_id': '0553210114',\n",
      "   'product_image': 'http://images.amazon.com/images/P/0553210114.01.MZZZZZZZ.jpg',\n",
      "   'product_price': nan,\n",
      "   'product_soup': 'The Red Badge of Courage (Bantam Classics) STEPHEN CRANE '\n",
      "                   'Bantam',\n",
      "   'product_tags': nan,\n",
      "   'product_title': 'The Red Badge of Courage (Bantam Classics)'},\n",
      "  1.0)]\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "\n",
    "engineRec = KNNWithMeansRecommender(productdf, product_data)\n",
    "engineRec.train(transactions=transactiondf, auto_save=True)\n",
    "# engineRec.load()\n",
    "  \n",
    "  \n",
    "\n",
    "randomProduct = engineRec.get_random_recommendation()[0]\n",
    "pprint.pprint(randomProduct)\n",
    "\n",
    "print('======== RECOMENDATIONS SINGLE CASE =========== ')\n",
    "rec = engineRec.recommend_from_single(randomProduct['id'])\n",
    "pprint.pprint(rec)\n",
    "\n",
    "\n",
    "# print(\"============= RECOMENDATIONS RECOMMENDATIONS ============\")\n",
    "# tansactions = ['0590353403', '0439139597']\n",
    "# recomendations = engineRec.recommend_from_past(tansactions)\n",
    "# pprint.pprint(recomendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
