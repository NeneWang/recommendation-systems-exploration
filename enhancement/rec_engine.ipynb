{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking at ../data/products_books_v1_10_10.csv\n",
      "357929\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>0060520507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>0060930934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>0060951303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>0140154078</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  user_id  product_id  rate\n",
       "0  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  002542730X    10\n",
       "1  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  0060520507     0\n",
       "2  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  0060930934     0\n",
       "3  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  0060951303     0\n",
       "4  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  0140154078     6"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pprint\n",
    "\n",
    "product_data = {\n",
    "    \"data_context\": \"books\",\n",
    "    \"product_filepath\": \"data/products_books_v1_10_10.csv\",\n",
    "    \"transactions_filepath\": \"data/transactions_books_v1_10_10.csv\",\n",
    "    \"features\": [\"product_title\", \"product_image\", \"product_soup\", \"product_images\"],\n",
    "    \"version\": \"1.0\",\n",
    "    \"unique_name\": \"_books_v1_10_10\",\n",
    "}\n",
    "\n",
    "print(\"looking at\", \"../\" + product_data[\"product_filepath\"])\n",
    "\n",
    "productdf =  pd.read_csv(\"../\" + product_data[\"product_filepath\"])\n",
    "transactiondf = pd.read_csv(\"../\" + product_data[\"transactions_filepath\"])\n",
    "\n",
    "\n",
    "print(len(transactiondf))\n",
    "productdf.head()\n",
    "transactiondf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>243</th>\n",
       "      <th>254</th>\n",
       "      <th>383</th>\n",
       "      <th>388</th>\n",
       "      <th>424</th>\n",
       "      <th>446</th>\n",
       "      <th>487</th>\n",
       "      <th>503</th>\n",
       "      <th>507</th>\n",
       "      <th>638</th>\n",
       "      <th>...</th>\n",
       "      <th>278221</th>\n",
       "      <th>278314</th>\n",
       "      <th>278356</th>\n",
       "      <th>278390</th>\n",
       "      <th>278418</th>\n",
       "      <th>278522</th>\n",
       "      <th>278535</th>\n",
       "      <th>278582</th>\n",
       "      <th>278633</th>\n",
       "      <th>278843</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0002005018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002251760</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000649840X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006547834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006550576</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id     243     254     383     388     424     446     487     503     \\\n",
       "product_id                                                                   \n",
       "0002005018     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "0002251760     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "000649840X     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "0006547834     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "0006550576     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "user_id     507     638     ...  278221  278314  278356  278390  278418  \\\n",
       "product_id                  ...                                           \n",
       "0002005018     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "0002251760     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "000649840X     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "0006547834     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "0006550576     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "user_id     278522  278535  278582  278633  278843  \n",
       "product_id                                          \n",
       "0002005018     0.0     0.0     0.0     0.0     0.0  \n",
       "0002251760     0.0     0.0     0.0     0.0     0.0  \n",
       "000649840X     0.0     0.0     0.0     0.0     0.0  \n",
       "0006547834     0.0     0.0     0.0     0.0     0.0  \n",
       "0006550576     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 6147 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = transactiondf.pivot_table(index=\"product_id\", columns=\"user_id\", values=\"rate\")\n",
    "pt.fillna(0, inplace=True)\n",
    "pt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt len 13011\n"
     ]
    }
   ],
   "source": [
    "print('pt len', len(pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pt\n",
    "pt.to_csv(\"cosine_pv_book.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "similarity_score = cosine_similarity(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Store\n",
    "file_pi = open('filename_pi.obj', 'w') \n",
    "pickle.dump(object_pi, file_pi)\n",
    "\n",
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "\n",
    "file_simscr = open('filesimscr', 'wb')\n",
    "pickle.dump(similarity_score, file_simscr)\n",
    "file_simscr.close()  # It's good practice to close the file after writing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_simscr = open('filesimscr', 'rb')\n",
    "loaded_similarity_score = pickle.load(file_simscr)\n",
    "file_simscr.close()  # Close the file after reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.13181175, ..., 0.18650096, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.13181175, 0.        , 1.        , ..., 0.08834522, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.18650096, 0.        , 0.08834522, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationAbstract():\n",
    "    strategy_name: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    version: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_past_recommendation: bool = \"REQUIRES IMPLEMENTATION\"\n",
    "\n",
    "    def __init__(self, products, product_data):\n",
    "        self.products = products\n",
    "        self.product_data = product_data\n",
    "        self.model = None\n",
    "\n",
    "    def loadModel(self, model_code):\n",
    "        \"\"\"\n",
    "        Load the model\n",
    "        \"\"\"\n",
    "        self.model = model_code\n",
    "\n",
    "    def train(self, verbose=False, transactions_train=None, users_train=None):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        # ... do training\n",
    "        # self.model = trained_model\n",
    "        \n",
    "    def get_random_recommendation(self, n=1):\n",
    "        \"\"\"\n",
    "        Get random recommendations\n",
    "        \"\"\"\n",
    "        # Select n random rows from the DataFrame\n",
    "        random_rows = self.products.sample(n)\n",
    "        # Convert the selected rows to a list of dictionaries\n",
    "        random_recommendations = random_rows.to_dict(orient='records')\n",
    "        return random_recommendations\n",
    "\n",
    "\n",
    "\n",
    "    def saveModel(self, model_code):\n",
    "        \"\"\"\n",
    "        Save the model\n",
    "        \"\"\"\n",
    "        # ... saves the model\n",
    "\n",
    "    def id_to_productDetail(self, product_id: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Return product details based on product id.\n",
    "        \"\"\"\n",
    "        return self.id_to_products.get(product_id)\n",
    "\n",
    "    def ids_to_products(self, ids: List[str]) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Return product details for a list of product ids.\n",
    "        \"\"\"\n",
    "        return [self.id_to_productDetail(id) for id in ids]\n",
    "\n",
    "    def like(self, keyword: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return a list of products that contain the given keyword in their title.\n",
    "        \"\"\"\n",
    "        return [product for product in self.products if keyword in product['product_title']]\n",
    "\n",
    "    def recommend_from_single(self, product_id: str, n=5) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        target_name = self.id_to_productDetail(product_id)['product_title']\n",
    "        keywords = target_name.split(\" \")\n",
    "        recommendations = []\n",
    "        for keyword in keywords:\n",
    "            recommendations.extend(self.like(keyword))\n",
    "        \n",
    "        random.shuffle(recommendations)\n",
    "        return recommendations[:n]\n",
    "\n",
    "    def recommend_from_past(self, user_transactions, n=10) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return recommendations based on past user transactions.\n",
    "        \"\"\"\n",
    "        rec = []\n",
    "        for transaction in user_transactions:\n",
    "            rec.extend(self.recommend_from_single(transaction['product_id']))\n",
    "        random.shuffle(rec)\n",
    "        return rec[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the class using cosine Similarity.\n",
    "\n",
    "class CosineSimilarityRecommender(RecommendationAbstract):\n",
    "    strategy_name: str = \"Cosine Similarity\"\n",
    "    slug_name: str = \"cosine_similarity\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data):\n",
    "        super().__init__(products, product_data)\n",
    "        self.products = products\n",
    "        self.pt = []\n",
    "        self.sim_score = None\n",
    "        \n",
    "    def train(self, transactions, auto_save=True):\n",
    "        self.pt = transactions.pivot_table(index=\"product_id\", columns=\"user_id\", values=\"rate\")\n",
    "        self.pt.fillna(0, inplace=True)\n",
    "        self.sim_score = cosine_similarity(pt)\n",
    "        if auto_save:\n",
    "            self.save()\n",
    "        \n",
    "        \n",
    "    def get_filename(self):\n",
    "        return  self.slug_name + self.product_data[\"unique_name\"] + \".pik\"\n",
    "    \n",
    "    def save(self):\n",
    "        # Store self.pt\n",
    "        filename = self.get_filename()\n",
    "        file_simscr = open(filename, 'wb')\n",
    "        pickle.dump(self.sim_score, file_simscr)\n",
    "        file_simscr.close()\n",
    "        \n",
    "    def load(self):\n",
    "        filename = self.get_filename()\n",
    "        file_simscr = open(filename, 'rb')\n",
    "        self.sim_score = pickle.load(file_simscr)\n",
    "        file_simscr.close()\n",
    "        \n",
    "\n",
    "    def recommend_from_single(self, product_id, n=5):\n",
    "        # print('product_id', product_id, self.products['id'] == product_id)\n",
    "        # Find the index of the product_id in the DataFrame\n",
    "        index = np.where(self.products['id'] == product_id)[0][0]\n",
    "        print('index', index)\n",
    "        # Get similarity scores for the product at the found index\n",
    "        similar_products = sorted(enumerate(self.sim_score[index]), key=lambda x: x[1], reverse=True)[1:n+1]\n",
    "        # Retrieve the similar products using their indices and return them\n",
    "        rec = [self.products.iloc[similar_product[0]] for similar_product in similar_products]\n",
    "        return rec\n",
    "\n",
    "\n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        rec = []\n",
    "        for transaction in transactions:\n",
    "            rec.extend(self.recommend_from_single(transaction['product_id']))\n",
    "        random.shuffle(rec)\n",
    "        return rec[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "cosineRecommender = CosineSimilarityRecommender(productdf, product_data)\n",
    "# Train.\n",
    "# cosineRecommender.train(transactiondf, auto_save=True)\n",
    "cosineRecommender.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0786808012',\n",
      " 'product_image': 'http://images.amazon.com/images/P/0786808012.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': 'Artemis Fowl (Artemis Fowl, Book 1) Eoin Colfer Miramax Kids',\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'Artemis Fowl (Artemis Fowl, Book 1)'}\n",
      "======== RECOMENDATIONS =========== \n",
      "index 5926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[id                                                      0020442106\n",
       " product_title    The Last Battle (The Chronicles of Narnia Book 7)\n",
       " product_image    http://images.amazon.com/images/P/0020442106.0...\n",
       " product_price                                                  NaN\n",
       " product_soup     The Last Battle (The Chronicles of Narnia Book...\n",
       " product_tags                                                   NaN\n",
       " Name: 7550, dtype: object,\n",
       " id                                                      0345428064\n",
       " product_title                                       Remote Control\n",
       " product_image    http://images.amazon.com/images/P/0345428064.0...\n",
       " product_price                                                  NaN\n",
       " product_soup            Remote Control Andy McNab Ballantine Books\n",
       " product_tags                                                   NaN\n",
       " Name: 10931, dtype: object,\n",
       " id                                                      0060008873\n",
       " product_title                                           Do No Harm\n",
       " product_image    http://images.amazon.com/images/P/0060008873.0...\n",
       " product_price                                                  NaN\n",
       " product_soup                  Do No Harm Gregg Hurwitz HarperTorch\n",
       " product_tags                                                   NaN\n",
       " Name: 7466, dtype: object,\n",
       " id                                                      0515130389\n",
       " product_title                                        Carolina Moon\n",
       " product_image    http://images.amazon.com/images/P/0515130389.0...\n",
       " product_price                                                  NaN\n",
       " product_soup                 Carolina Moon Nora Roberts Jove Books\n",
       " product_tags                                                   NaN\n",
       " Name: 1260, dtype: object,\n",
       " id                                                      0316780375\n",
       " product_title    The Weight of Water : A Novel Tag: Author of R...\n",
       " product_image    http://images.amazon.com/images/P/0316780375.0...\n",
       " product_price                                                  NaN\n",
       " product_soup     The Weight of Water : A Novel Tag: Author of R...\n",
       " product_tags                                                   NaN\n",
       " Name: 3057, dtype: object]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use JSON parse.\n",
    "# cosineRecommender.get_random_recommendation()\n",
    "randomid = cosineRecommender.get_random_recommendation()[0]\n",
    "pprint.pprint(randomid)\n",
    "print('======== RECOMENDATIONS =========== ')\n",
    "cosineRecommender.recommend_from_single(randomid['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import string\n",
    "\n",
    "class WordVecBodyRecommender(RecommendationAbstract):\n",
    "    \n",
    "    strategy_name: str = \"WordVec\"\n",
    "    slug_name: str = \"wordvec\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data):\n",
    "        \"\"\"\n",
    "        Initialize the recommender with a pre-trained Word2Vec model and a dataframe of books.\n",
    "        \"\"\"\n",
    "        super().__init__(products, product_data)\n",
    "        self.products_df = products\n",
    "        self.model = None\n",
    "        self.train()\n",
    "\n",
    "    def train(self, save_model=False):\n",
    "        \"\"\"\n",
    "        Train the Word2Vec model on the book descriptions.\n",
    "        \"\"\"\n",
    "        self.model = Word2Vec(sentences=self.products['product_soup'].str.split(), vector_size=100, window=5, min_count=1, workers=4)\n",
    "        if save_model:\n",
    "            self.save()\n",
    "        \n",
    "\n",
    "        # Updated function to recommend books based on similar word vectors\n",
    "    def recommend_books_updated(self, input_text, top_n=5):\n",
    "        input_text = input_text.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "        vector = self.model.wv[input_text].mean(axis=0)\n",
    "        similar_vectors = self.model.wv.similar_by_vector(vector, topn=top_n + 10)  # Retrieve more results to filter unique titles\n",
    "        recommended_titles = []\n",
    "        for book_vector in similar_vectors:\n",
    "            similar_title = self.products.loc[self.products['product_soup'].apply(lambda x: any(word in x for word in input_text)), 'product_title'].unique()\n",
    "            for title in similar_title:\n",
    "                if title not in recommended_titles and len(recommended_titles) < top_n:\n",
    "                    recommended_titles.append(title)\n",
    "        return recommended_titles\n",
    "      \n",
    "    def recommend_from_single(self, product_id, n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        # Get the product_soup for the given product_id\n",
    "        product_soup = self.products.loc[self.products['id'] == product_id, 'product_soup'].values[0]\n",
    "        # Use the recommend_books_updated function to recommend books based on the product_soup\n",
    "        recommendations = self.recommend_books_updated(product_soup, top_n=n)\n",
    "        return recommendations\n",
    "    \n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        \"\"\"\n",
    "        Return recommendations based on past transactions.\n",
    "        \"\"\"\n",
    "        # Concatenate product_soup from past transactions\n",
    "        past_text = ' '.join(self.products.loc[self.products['id'].isin(transactions), 'product_soup'])\n",
    "        # Use the self.recommend_books_updated function to recommend books based on past transactions\n",
    "        recommendations = self.recommend_books_updated(past_text, top_n=n)\n",
    "        return recommendations\n",
    "        \n",
    "        \n",
    "    def get_filename(self):\n",
    "        return  self.slug_name + self.product_data[\"unique_name\"] + \".model\"\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save the computed book vectors to a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        filemodel = open(filename, 'wb')\n",
    "        pickle.dump(self.model, filemodel)\n",
    "        filemodel.close()\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load the book vectors from a file.\n",
    "        \"\"\"\n",
    "        \n",
    "        filename = self.get_filename()\n",
    "        filemodel = open(filename, 'rb')\n",
    "        self.model = pickle.load(filemodel)\n",
    "        filemodel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementationa nd test.\n",
    "\n",
    "wordvecRecommender = WordVecBodyRecommender(productdf, product_data)\n",
    "# Train.\n",
    "# wordvecRecommender.train(transactiondf, auto_save=True)\n",
    "wordvecRecommender.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Tess of the D'Urbervilles (Wordsworth Classics)\",\n",
       " 'Midnight in the Garden of Good and Evil: A Savannah Story',\n",
       " 'Blood Oath',\n",
       " 'Whisper of Evil (Hooper, Kay. Evil Trilogy.)',\n",
       " 'Wish You Well']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get random and recommend.\n",
    "\n",
    "randomProduct = wordvecRecommender.get_random_recommendation()[0]\n",
    "wordvecRecommender.recommend_from_single(randomProduct['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WordVecBodyRecommender(RecommendationAbstract):\n",
    "    \n",
    "    strategy_name: str = \"WordVec\"\n",
    "    slug_name: str = \"wordvec\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data):\n",
    "        \"\"\"\n",
    "        Initialize the recommender with a pre-trained Word2Vec model and a dataframe of books.\n",
    "        \"\"\"\n",
    "        super().__init__(products, product_data)\n",
    "        self.products_df = products\n",
    "        self.model = None\n",
    "        self.train()\n",
    "\n",
    "    def train(self, save_model=False):\n",
    "        \"\"\"\n",
    "        Train the Word2Vec model on the book descriptions.\n",
    "        \"\"\"\n",
    "        self.model = Word2Vec(sentences=self.products['product_soup'].str.split(), vector_size=100, window=5, min_count=1, workers=4)\n",
    "        if save_model:\n",
    "            self.save()\n",
    "        \n",
    "\n",
    "        # Updated function to recommend books based on similar word vectors\n",
    "    def recommend_books_updated(self, input_text, top_n=5):\n",
    "        input_text = input_text.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "        vector = self.model.wv[input_text].mean(axis=0)\n",
    "        similar_vectors = self.model.wv.similar_by_vector(vector, topn=top_n + 10)  # Retrieve more results to filter unique titles\n",
    "        recommended_titles = []\n",
    "        for book_vector in similar_vectors:\n",
    "            similar_title = self.products.loc[self.products['product_soup'].apply(lambda x: any(word in x for word in input_text)), 'product_title'].unique()\n",
    "            for title in similar_title:\n",
    "                if title not in recommended_titles and len(recommended_titles) < top_n:\n",
    "                    recommended_titles.append(title)\n",
    "        return recommended_titles\n",
    "      \n",
    "    def recommend_from_single(self, product_id, n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        # Get the product_soup for the given product_id\n",
    "        product_soup = self.products.loc[self.products['id'] == product_id, 'product_soup'].values[0]\n",
    "        # Use the recommend_books_updated function to recommend books based on the product_soup\n",
    "        recommendations = self.recommend_books_updated(product_soup, top_n=n)\n",
    "        return recommendations\n",
    "    \n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        \"\"\"\n",
    "        Return recommendations based on past transactions.\n",
    "        \"\"\"\n",
    "        # Concatenate product_soup from past transactions\n",
    "        past_text = ' '.join(self.products.loc[self.products['id'].isin(transactions), 'product_soup'])\n",
    "        # Use the self.recommend_books_updated function to recommend books based on past transactions\n",
    "        recommendations = self.recommend_books_updated(past_text, top_n=n)\n",
    "        return recommendations\n",
    "        \n",
    "        \n",
    "    def get_filename(self):\n",
    "        return  self.slug_name + self.product_data[\"unique_name\"] + \".model\"\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save the computed book vectors to a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        filemodel = open(filename, 'wb')\n",
    "        pickle.dump(self.model, filemodel)\n",
    "        filemodel.close()\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load the book vectors from a file.\n",
    "        \"\"\"\n",
    "        \n",
    "        filename = self.get_filename()\n",
    "        filemodel = open(filename, 'rb')\n",
    "        self.model = pickle.load(filemodel)\n",
    "        filemodel.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
