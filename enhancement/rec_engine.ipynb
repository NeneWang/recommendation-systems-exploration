{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking at ../data/products_books_v1_10_10.csv\n",
      "357929\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>0060520507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>0060930934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>0060951303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>0140154078</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  user_id  product_id  rate\n",
       "0  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  002542730X    10\n",
       "1  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  0060520507     0\n",
       "2  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  0060930934     0\n",
       "3  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  0060951303     0\n",
       "4  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  0140154078     6"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pprint\n",
    "\n",
    "product_data = {\n",
    "    \"data_context\": \"books\",\n",
    "    \"product_filepath\": \"data/products_books_v1_10_10.csv\",\n",
    "    \"transactions_filepath\": \"data/transactions_books_v1_10_10.csv\",\n",
    "    \"features\": [\"product_title\", \"product_image\", \"product_soup\", \"product_images\"],\n",
    "    \"version\": \"1.0\",\n",
    "    \"unique_name\": \"_books_v1_10_10\",\n",
    "}\n",
    "\n",
    "print(\"looking at\", \"../\" + product_data[\"product_filepath\"])\n",
    "\n",
    "productdf =  pd.read_csv(\"../\" + product_data[\"product_filepath\"])\n",
    "transactiondf = pd.read_csv(\"../\" + product_data[\"transactions_filepath\"])\n",
    "\n",
    "\n",
    "print(len(transactiondf))\n",
    "productdf.head()\n",
    "transactiondf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>243</th>\n",
       "      <th>254</th>\n",
       "      <th>383</th>\n",
       "      <th>388</th>\n",
       "      <th>424</th>\n",
       "      <th>446</th>\n",
       "      <th>487</th>\n",
       "      <th>503</th>\n",
       "      <th>507</th>\n",
       "      <th>638</th>\n",
       "      <th>...</th>\n",
       "      <th>278221</th>\n",
       "      <th>278314</th>\n",
       "      <th>278356</th>\n",
       "      <th>278390</th>\n",
       "      <th>278418</th>\n",
       "      <th>278522</th>\n",
       "      <th>278535</th>\n",
       "      <th>278582</th>\n",
       "      <th>278633</th>\n",
       "      <th>278843</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0002005018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002251760</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000649840X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006547834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006550576</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id     243     254     383     388     424     446     487     503     \\\n",
       "product_id                                                                   \n",
       "0002005018     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "0002251760     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "000649840X     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "0006547834     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "0006550576     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "user_id     507     638     ...  278221  278314  278356  278390  278418  \\\n",
       "product_id                  ...                                           \n",
       "0002005018     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "0002251760     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "000649840X     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "0006547834     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "0006550576     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "user_id     278522  278535  278582  278633  278843  \n",
       "product_id                                          \n",
       "0002005018     0.0     0.0     0.0     0.0     0.0  \n",
       "0002251760     0.0     0.0     0.0     0.0     0.0  \n",
       "000649840X     0.0     0.0     0.0     0.0     0.0  \n",
       "0006547834     0.0     0.0     0.0     0.0     0.0  \n",
       "0006550576     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 6147 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = transactiondf.pivot_table(index=\"product_id\", columns=\"user_id\", values=\"rate\")\n",
    "pt.fillna(0, inplace=True)\n",
    "pt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt len 13011\n"
     ]
    }
   ],
   "source": [
    "print('pt len', len(pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pt\n",
    "pt.to_csv(\"cosine_pv_book.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "similarity_score = cosine_similarity(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Store\n",
    "file_pi = open('filename_pi.obj', 'w') \n",
    "pickle.dump(object_pi, file_pi)\n",
    "\n",
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "\n",
    "file_simscr = open('filesimscr', 'wb')\n",
    "pickle.dump(similarity_score, file_simscr)\n",
    "file_simscr.close()  # It's good practice to close the file after writing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_simscr = open('filesimscr', 'rb')\n",
    "loaded_similarity_score = pickle.load(file_simscr)\n",
    "file_simscr.close()  # Close the file after reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.13181175, ..., 0.18650096, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.13181175, 0.        , 1.        , ..., 0.08834522, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.18650096, 0.        , 0.08834522, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RecommendationAbstract():\n",
    "    strategy_name: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    version: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_past_recommendation: bool = \"REQUIRES IMPLEMENTATION\"\n",
    "\n",
    "    def __init__(self, products, product_data):\n",
    "        self.products = products\n",
    "        self.product_data = product_data\n",
    "        self.model = None\n",
    "        # populate id_to_products\n",
    "        self.id_to_products = {}\n",
    "        for product in self.products.to_dict(orient='records'):\n",
    "            self.id_to_products[product['id']] = product\n",
    "\n",
    "    def loadModel(self, model_code):\n",
    "        \"\"\"\n",
    "        Load the model\n",
    "        \"\"\"\n",
    "        self.model = model_code\n",
    "\n",
    "    def train(self, verbose=False, transactions_train=None, users_train=None):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        # ... do training\n",
    "        # self.model = trained_model\n",
    "        \n",
    "    def get_random_recommendation(self, n=1):\n",
    "        \"\"\"\n",
    "        Get random recommendations\n",
    "        \"\"\"\n",
    "        # Select n random rows from the DataFrame\n",
    "        random_rows = self.products.sample(n)\n",
    "        # Convert the selected rows to a list of dictionaries\n",
    "        random_recommendations = random_rows.to_dict(orient='records')\n",
    "        return random_recommendations\n",
    "\n",
    "\n",
    "\n",
    "    def saveModel(self, model_code):\n",
    "        \"\"\"\n",
    "        Save the model\n",
    "        \"\"\"\n",
    "        # ... saves the model\n",
    "\n",
    "    def id_to_productDetail(self, product_id: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Return product details based on product id.\n",
    "        \"\"\"\n",
    "        return self.id_to_products.get(product_id)\n",
    "\n",
    "    def ids_to_products(self, ids: List[str]) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Return product details for a list of product ids.\n",
    "        \"\"\"\n",
    "        return [self.id_to_productDetail(id) for id in ids]\n",
    "\n",
    "    def like(self, keyword: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return a list of products that contain the given keyword in their title.\n",
    "        \"\"\"\n",
    "        return [product for product in self.products if keyword in product['product_title']]\n",
    "\n",
    "    def recommend_from_single(self, product_id: str, n=5) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        target_name = self.id_to_productDetail(product_id)['product_title']\n",
    "        keywords = target_name.split(\" \")\n",
    "        recommendations = []\n",
    "        for keyword in keywords:\n",
    "            recommendations.extend(self.like(keyword))\n",
    "        \n",
    "        random.shuffle(recommendations)\n",
    "        return recommendations[:n]\n",
    "\n",
    "    def recommend_from_past(self, user_transactions, n=10) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return recommendations based on past user transactions.\n",
    "        \"\"\"\n",
    "        rec = []\n",
    "        for transaction in user_transactions:\n",
    "            rec.extend(self.recommend_from_single(transaction['product_id']))\n",
    "        random.shuffle(rec)\n",
    "        return rec[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the class using cosine Similarity.\n",
    "\n",
    "class CosineSimilarityRecommender(RecommendationAbstract):\n",
    "    strategy_name: str = \"Cosine Similarity\"\n",
    "    slug_name: str = \"cosine_similarity\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data):\n",
    "        super().__init__(products, product_data)\n",
    "        self.products = products\n",
    "        self.pt = []\n",
    "        self.sim_score = None\n",
    "        \n",
    "    def train(self, transactions, auto_save=True):\n",
    "        self.pt = transactions.pivot_table(index=\"product_id\", columns=\"user_id\", values=\"rate\")\n",
    "        self.pt.fillna(0, inplace=True)\n",
    "        self.sim_score = cosine_similarity(self.pt)\n",
    "        if auto_save:\n",
    "            self.save()\n",
    "        \n",
    "        \n",
    "    def get_filename(self):\n",
    "        return  self.slug_name + self.product_data[\"unique_name\"] + \".pik\"\n",
    "    \n",
    "    def save(self):\n",
    "        # Store self.pt\n",
    "        filename = self.get_filename()\n",
    "        file_simscr = open(filename, 'wb')\n",
    "        pickle.dump(self.sim_score, file_simscr)\n",
    "        file_simscr.close()\n",
    "        \n",
    "    def load(self):\n",
    "        filename = self.get_filename()\n",
    "        file_simscr = open(filename, 'rb')\n",
    "        self.sim_score = pickle.load(file_simscr)\n",
    "        file_simscr.close()\n",
    "        \n",
    "\n",
    "    def recommend_from_single(self, product_id, n=5) -> List[Tuple[dict, float]]:\n",
    "        # print('product_id', product_id, self.products['id'] == product_id)\n",
    "        # Find the index of the product_id in the DataFrame\n",
    "        index = np.where(self.products['id'] == product_id)[0][0]\n",
    "        print('index', index)\n",
    "        # Get similarity scores for the product at the found index\n",
    "        similar_products = sorted(enumerate(self.sim_score[index]), key=lambda x: x[1], reverse=True)[1:n+1]\n",
    "        # Retrieve the similar products using their indices and return them\n",
    "        rec = [self.products.iloc[similar_product[0]] for similar_product in similar_products]\n",
    "        # Gets as list of product dictionary\n",
    "        recomendations_list = []\n",
    "        for product in rec:\n",
    "            recomendations_list.append(product.to_dict())\n",
    "        return recomendations_list\n",
    "\n",
    "\n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        rec = []\n",
    "        for transaction in transactions:\n",
    "            rec.extend(self.recommend_from_single(transaction['product_id']))\n",
    "        random.shuffle(rec)\n",
    "        return rec[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "cosineRecommender = CosineSimilarityRecommender(productdf, product_data)\n",
    "# Train.\n",
    "# cosineRecommender.train(transactiondf, auto_save=True)\n",
    "cosineRecommender.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0140434003',\n",
      " 'product_image': 'http://images.amazon.com/images/P/0140434003.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': 'Jane Eyre (Penguin Classics) Charlotte Bronte Penguin Books',\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'Jane Eyre (Penguin Classics)'}\n",
      "======== RECOMENDATIONS =========== \n",
      "index 3702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '0140314601',\n",
       "  'product_title': 'Playing Beatie Bow (Puffin Books)',\n",
       "  'product_image': 'http://images.amazon.com/images/P/0140314601.01.MZZZZZZZ.jpg',\n",
       "  'product_price': nan,\n",
       "  'product_soup': 'Playing Beatie Bow (Puffin Books) Ruth Park Puffin Books',\n",
       "  'product_tags': nan},\n",
       " {'id': '1551666103',\n",
       "  'product_title': 'The Mistress',\n",
       "  'product_image': 'http://images.amazon.com/images/P/1551666103.01.MZZZZZZZ.jpg',\n",
       "  'product_price': nan,\n",
       "  'product_soup': 'The Mistress Susan Wiggs Mira',\n",
       "  'product_tags': nan},\n",
       " {'id': '0060505885',\n",
       "  'product_title': 'The Scandalous Summer of Sissy LeBlanc : A Novel',\n",
       "  'product_image': 'http://images.amazon.com/images/P/0060505885.01.MZZZZZZZ.jpg',\n",
       "  'product_price': nan,\n",
       "  'product_soup': 'The Scandalous Summer of Sissy LeBlanc : A Novel Loraine Despres Perennial',\n",
       "  'product_tags': nan},\n",
       " {'id': '0451163508',\n",
       "  'product_title': 'Lie Down With Lions (Signet)',\n",
       "  'product_image': 'http://images.amazon.com/images/P/0451163508.01.MZZZZZZZ.jpg',\n",
       "  'product_price': nan,\n",
       "  'product_soup': 'Lie Down With Lions (Signet) Ken Follett Signet Book',\n",
       "  'product_tags': nan},\n",
       " {'id': '0553258001',\n",
       "  'product_title': 'The Cider House Rules',\n",
       "  'product_image': 'http://images.amazon.com/images/P/0553258001.01.MZZZZZZZ.jpg',\n",
       "  'product_price': nan,\n",
       "  'product_soup': 'The Cider House Rules John Irving Bantam Books',\n",
       "  'product_tags': nan}]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use JSON parse.\n",
    "# cosineRecommender.get_random_recommendation()\n",
    "randomid = cosineRecommender.get_random_recommendation()[0]\n",
    "pprint.pprint(randomid)\n",
    "print('======== RECOMENDATIONS =========== ')\n",
    "cosineRecommender.recommend_from_single(randomid['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "class WordVecBodyRecommender(RecommendationAbstract):\n",
    "    \n",
    "    strategy_name: str = \"WordVec\"\n",
    "    slug_name: str = \"wordvec\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data):\n",
    "        \"\"\"\n",
    "        Initialize the recommender with a pre-trained Word2Vec model and a dataframe of books.\n",
    "        \"\"\"\n",
    "        super().__init__(products, product_data)\n",
    "        self.products_df = products\n",
    "        self.model = None\n",
    "        print('id_to_products length', len(self.id_to_products))\n",
    "        self.train()\n",
    "\n",
    "\n",
    "    def train(self, auto_save=False):\n",
    "        \"\"\"\n",
    "        Train the Word2Vec model on the book titles.\n",
    "        \"\"\"\n",
    "        sentences = [title.lower().split() for title in self.products_df['product_soup']]\n",
    "        self.model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "        if auto_save:\n",
    "            self.save()\n",
    "            \n",
    "\n",
    "    def recommend_books_updated(self, input_text, top_n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on input text.\n",
    "        \"\"\"\n",
    "        input_text = input_text.lower().split()\n",
    "        vector = self.model.wv[input_text].mean(axis=0)\n",
    "        # Compute cosine similarity between the input vector and all product vectors\n",
    "        similarities = cosine_similarity([vector], self.model.wv.vectors)\n",
    "        # Get indices of top similar products\n",
    "        top_indices = similarities.argsort()[0][-top_n:]\n",
    "        recommended_products = []\n",
    "        for index in reversed(top_indices):  # Reversed to get top similarities first\n",
    "            product_title = self.products_df.iloc[index]['product_title']\n",
    "            confidence = similarities[0][index]\n",
    "            recommended_products.append((self.id_to_productDetail(self.products_df.iloc[index]['id']), confidence))\n",
    "        return recommended_products\n",
    "\n",
    "        \n",
    "    def recommend_from_single(self, product_id, n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        # Get the product_soup for the given product_id\n",
    "        product_soup = self.products.loc[self.products['id'] == product_id, 'product_soup'].values[0]\n",
    "        # Use the recommend_books_updated function to recommend books based on the product_soup\n",
    "        recommendations = self.recommend_books_updated(product_soup, top_n=n)\n",
    "        return recommendations\n",
    "\n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        \"\"\"\n",
    "        Return recommendations based on past transactions.\n",
    "        \"\"\"\n",
    "        # Concatenate product_soup from past transactions\n",
    "        past_text = ' '.join(self.products.loc[self.products['id'].isin(transactions), 'product_soup'])\n",
    "        # Use the self.recommend_books_updated function to recommend books based on past transactions\n",
    "        recommendations = self.recommend_books_updated(past_text, top_n=n)\n",
    "        return recommendations\n",
    "        \n",
    "        \n",
    "    def get_filename(self):\n",
    "        return  self.slug_name + self.product_data[\"unique_name\"] + \".model\"\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save the computed book vectors to a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        filemodel = open(filename, 'wb')\n",
    "        pickle.dump(self.model, filemodel)\n",
    "        filemodel.close()\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load the book vectors from a file.\n",
    "        \"\"\"\n",
    "        \n",
    "        filename = self.get_filename()\n",
    "        filemodel = open(filename, 'rb')\n",
    "        self.model = pickle.load(filemodel)\n",
    "        filemodel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_to_products length 13011\n"
     ]
    }
   ],
   "source": [
    "# Implementationa nd test.\n",
    "\n",
    "wordvecRecommender = WordVecBodyRecommender(productdf, product_data)\n",
    "# Train.\n",
    "wordvecRecommender.train()\n",
    "# wordvecRecommender.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0553258524',\n",
      " 'product_image': 'http://images.amazon.com/images/P/0553258524.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': 'Dragonsong (Harper Hall Trilogy) Anne McCaffrey Bantam',\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'Dragonsong (Harper Hall Trilogy)'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'id': '0743486226',\n",
       "   'product_title': 'Angels &amp; Demons',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0743486226.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Angels &amp; Demons Dan Brown Atria',\n",
       "   'product_tags': nan},\n",
       "  0.9962199),\n",
       " ({'id': '0743230051',\n",
       "   'product_title': \"He Sees You When You're Sleeping : A Novel\",\n",
       "   'product_image': 'http://images.amazon.com/images/P/0743230051.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': \"He Sees You When You're Sleeping : A Novel Mary Higgins Clark Scribner\",\n",
       "   'product_tags': nan},\n",
       "  0.99582505),\n",
       " ({'id': '0767905938',\n",
       "   'product_title': 'A Year by the Sea: Thoughts of an Unfinished Woman',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0767905938.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'A Year by the Sea: Thoughts of an Unfinished Woman Joan Anderson Broadway Books',\n",
       "   'product_tags': nan},\n",
       "  0.99532425),\n",
       " ({'id': '0452279690',\n",
       "   'product_title': 'Cavedweller',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0452279690.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Cavedweller Dorothy Allison Plume Books',\n",
       "   'product_tags': nan},\n",
       "  0.9942914),\n",
       " ({'id': '0345371984',\n",
       "   'product_title': 'Last Chance to See',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0345371984.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Last Chance to See Douglas Adams Ballantine Books',\n",
       "   'product_tags': nan},\n",
       "  0.99427116)]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get random and recommend.\n",
    "\n",
    "randomProduct = wordvecRecommender.get_random_recommendation()[0]\n",
    "pprint.pprint(randomProduct)\n",
    "wordvecRecommender.recommend_from_single(randomProduct['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TitleWordVecTitleyRecommender(RecommendationAbstract):\n",
    "    \n",
    "    strategy_name: str = \"TitleWordVec\"\n",
    "    slug_name: str = \"title_word_vec\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data):\n",
    "        \"\"\"\n",
    "        Initialize the recommender with a pre-trained Word2Vec model and a dataframe of books.\n",
    "        \"\"\"\n",
    "        super().__init__(products, product_data)\n",
    "        self.products_df = products\n",
    "        self.model = None\n",
    "        self.train()\n",
    "\n",
    "    def train(self, auto_save=False):\n",
    "        \"\"\"\n",
    "        Train the Word2Vec model on the book titles.\n",
    "        \"\"\"\n",
    "        sentences = [title.lower().split() for title in self.products_df['product_title']]\n",
    "        self.model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "        if auto_save:\n",
    "            self.save()\n",
    "\n",
    "    def recommend_from_single(self, product_id, n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        # Get the product_title for the given product_id\n",
    "        product_title = self.products_df.loc[self.products_df['id'] == product_id, 'product_title'].values[0]\n",
    "        # Use the recommend_books_updated function to recommend books based on the product_title\n",
    "        recommendations = self.recommend_books_updated(product_title, top_n=n)\n",
    "        return recommendations\n",
    "    \n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        \"\"\"\n",
    "        Return recommendations based on past transactions.\n",
    "        \"\"\"\n",
    "        # Concatenate product_titles from past transactions\n",
    "        past_titles = self.products_df.loc[self.products_df['id'].isin(transactions), 'product_title']\n",
    "        # Use the self.recommend_books_updated function to recommend books based on past transactions\n",
    "        recommendations = self.recommend_books_updated(' '.join(past_titles), top_n=n)\n",
    "        return recommendations\n",
    "\n",
    "        \n",
    "\n",
    "    def recommend_books_updated(self, input_text, top_n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on input text.\n",
    "        \"\"\"\n",
    "        input_text = input_text.lower().split()\n",
    "        vector = self.model.wv[input_text].mean(axis=0)\n",
    "        # Compute cosine similarity between the input vector and all product vectors\n",
    "        similarities = cosine_similarity([vector], self.model.wv.vectors)\n",
    "        # Get indices of top similar products\n",
    "        top_indices = similarities.argsort()[0][-top_n:]\n",
    "        recommended_products = []\n",
    "        for index in reversed(top_indices):  # Reversed to get top similarities first\n",
    "            product_title = self.products_df.iloc[index]['product_title']\n",
    "            confidence = similarities[0][index]\n",
    "            recommended_products.append((self.id_to_productDetail(self.products_df.iloc[index]['id']), confidence))\n",
    "        return recommended_products\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save the computed book vectors to a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        with open(filename, 'wb') as filemodel:\n",
    "            pickle.dump(self.model, filemodel)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load the book vectors from a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        with open(filename, 'rb') as filemodel:\n",
    "            self.model = pickle.load(filemodel)\n",
    "\n",
    "    def get_filename(self):\n",
    "        \"\"\"\n",
    "        Get the filename for saving/loading the model.\n",
    "        \"\"\"\n",
    "        return self.slug_name + self.product_data[\"unique_name\"] + \".model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random and recommend.\n",
    "wordvecRecommender = TitleWordVecTitleyRecommender(productdf, product_data)\n",
    "# Train.\n",
    "wordvecRecommender.train( auto_save=True)\n",
    "# wordvecRecommender.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0312252617',\n",
      " 'product_image': 'http://images.amazon.com/images/P/0312252617.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': \"Fast Women Jennifer Crusie St. Martin's Press\",\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'Fast Women'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'id': '0345433173',\n",
       "   'product_title': 'The Tall Pine Polka',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0345433173.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'The Tall Pine Polka Lorna Landvik Ballantine Books',\n",
       "   'product_tags': nan},\n",
       "  0.9994216),\n",
       " ({'id': '0345311396',\n",
       "   'product_title': 'Private Screening',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0345311396.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Private Screening Richard North Patterson Ballantine Books',\n",
       "   'product_tags': nan},\n",
       "  0.9988701),\n",
       " ({'id': '042518630X',\n",
       "   'product_title': 'Purity in Death',\n",
       "   'product_image': 'http://images.amazon.com/images/P/042518630X.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Purity in Death J.D. Robb Berkley Publishing Group',\n",
       "   'product_tags': nan},\n",
       "  0.99883413),\n",
       " ({'id': '0452264464',\n",
       "   'product_title': 'Beloved (Plume Contemporary Fiction)',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0452264464.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Beloved (Plume Contemporary Fiction) Toni Morrison Plume',\n",
       "   'product_tags': nan},\n",
       "  0.9988065),\n",
       " ({'id': '0449005615',\n",
       "   'product_title': 'Seabiscuit: An American Legend',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0449005615.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Seabiscuit: An American Legend LAURA HILLENBRAND Ballantine Books',\n",
       "   'product_tags': nan},\n",
       "  0.9987772)]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tansactions = ['1551665204', '055357538']\n",
    "\n",
    "randomProduct = wordvecRecommender.get_random_recommendation()[0]\n",
    "pprint.pprint(randomProduct)\n",
    "wordvecRecommender.recommend_from_single(randomProduct['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
