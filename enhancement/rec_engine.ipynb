{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking at ../data/products_books_v1_10_10.csv\n",
      "357929\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>0060520507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>0060930934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>0060951303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cde7cee0-e36b-410f-96fa-fe246abd5fdf</td>\n",
       "      <td>276925</td>\n",
       "      <td>0140154078</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  user_id  product_id  rate\n",
       "0  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  002542730X    10\n",
       "1  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  0060520507     0\n",
       "2  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  0060930934     0\n",
       "3  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  0060951303     0\n",
       "4  cde7cee0-e36b-410f-96fa-fe246abd5fdf   276925  0140154078     6"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pprint\n",
    "\n",
    "product_data = {\n",
    "    \"data_context\": \"books\",\n",
    "    \"product_filepath\": \"data/products_books_v1_10_10.csv\",\n",
    "    \"transactions_filepath\": \"data/transactions_books_v1_10_10.csv\",\n",
    "    \"features\": [\"product_title\", \"product_image\", \"product_soup\", \"product_images\"],\n",
    "    \"version\": \"1.0\",\n",
    "    \"unique_name\": \"_books_v1_10_10\",\n",
    "}\n",
    "\n",
    "print(\"looking at\", \"../\" + product_data[\"product_filepath\"])\n",
    "\n",
    "productdf =  pd.read_csv(\"../\" + product_data[\"product_filepath\"])\n",
    "transactiondf = pd.read_csv(\"../\" + product_data[\"transactions_filepath\"])\n",
    "\n",
    "\n",
    "print(len(transactiondf))\n",
    "productdf.head()\n",
    "transactiondf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>243</th>\n",
       "      <th>254</th>\n",
       "      <th>383</th>\n",
       "      <th>388</th>\n",
       "      <th>424</th>\n",
       "      <th>446</th>\n",
       "      <th>487</th>\n",
       "      <th>503</th>\n",
       "      <th>507</th>\n",
       "      <th>638</th>\n",
       "      <th>...</th>\n",
       "      <th>278221</th>\n",
       "      <th>278314</th>\n",
       "      <th>278356</th>\n",
       "      <th>278390</th>\n",
       "      <th>278418</th>\n",
       "      <th>278522</th>\n",
       "      <th>278535</th>\n",
       "      <th>278582</th>\n",
       "      <th>278633</th>\n",
       "      <th>278843</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0002005018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002251760</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000649840X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006547834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006550576</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id     243     254     383     388     424     446     487     503     \\\n",
       "product_id                                                                   \n",
       "0002005018     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "0002251760     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "000649840X     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "0006547834     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "0006550576     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "user_id     507     638     ...  278221  278314  278356  278390  278418  \\\n",
       "product_id                  ...                                           \n",
       "0002005018     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "0002251760     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "000649840X     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "0006547834     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "0006550576     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "user_id     278522  278535  278582  278633  278843  \n",
       "product_id                                          \n",
       "0002005018     0.0     0.0     0.0     0.0     0.0  \n",
       "0002251760     0.0     0.0     0.0     0.0     0.0  \n",
       "000649840X     0.0     0.0     0.0     0.0     0.0  \n",
       "0006547834     0.0     0.0     0.0     0.0     0.0  \n",
       "0006550576     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 6147 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = transactiondf.pivot_table(index=\"product_id\", columns=\"user_id\", values=\"rate\")\n",
    "pt.fillna(0, inplace=True)\n",
    "pt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt len 13011\n"
     ]
    }
   ],
   "source": [
    "print('pt len', len(pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pt\n",
    "pt.to_csv(\"cosine_pv_book.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "similarity_score = cosine_similarity(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Store\n",
    "file_pi = open('filename_pi.obj', 'w') \n",
    "pickle.dump(object_pi, file_pi)\n",
    "\n",
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "\n",
    "file_simscr = open('filesimscr', 'wb')\n",
    "pickle.dump(similarity_score, file_simscr)\n",
    "file_simscr.close()  # It's good practice to close the file after writing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_simscr = open('filesimscr', 'rb')\n",
    "loaded_similarity_score = pickle.load(file_simscr)\n",
    "file_simscr.close()  # Close the file after reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.13181175, ..., 0.18650096, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.13181175, 0.        , 1.        , ..., 0.08834522, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.18650096, 0.        , 0.08834522, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RecommendationAbstract():\n",
    "    strategy_name: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    version: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_past_recommendation: bool = \"REQUIRES IMPLEMENTATION\"\n",
    "\n",
    "    def __init__(self, products, product_data):\n",
    "        self.products = products\n",
    "        self.product_data = product_data\n",
    "        self.model = None\n",
    "        # populate id_to_products\n",
    "        self.id_to_products = {}\n",
    "        for product in self.products.to_dict(orient='records'):\n",
    "            self.id_to_products[product['id']] = product\n",
    "\n",
    "    def loadModel(self, model_code):\n",
    "        \"\"\"\n",
    "        Load the model\n",
    "        \"\"\"\n",
    "        self.model = model_code\n",
    "\n",
    "    def train(self, verbose=False, transactions_train=None, users_train=None):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        # ... do training\n",
    "        # self.model = trained_model\n",
    "        \n",
    "    def get_random_recommendation(self, n=1):\n",
    "        \"\"\"\n",
    "        Get random recommendations\n",
    "        \"\"\"\n",
    "        # Select n random rows from the DataFrame\n",
    "        random_rows = self.products.sample(n)\n",
    "        # Convert the selected rows to a list of dictionaries\n",
    "        random_recommendations = random_rows.to_dict(orient='records')\n",
    "        return random_recommendations\n",
    "\n",
    "\n",
    "\n",
    "    def saveModel(self, model_code):\n",
    "        \"\"\"\n",
    "        Save the model\n",
    "        \"\"\"\n",
    "        # ... saves the model\n",
    "\n",
    "    def id_to_productDetail(self, product_id: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Return product details based on product id.\n",
    "        \"\"\"\n",
    "        return self.id_to_products.get(product_id)\n",
    "\n",
    "    def ids_to_products(self, ids: List[str]) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Return product details for a list of product ids.\n",
    "        \"\"\"\n",
    "        return [self.id_to_productDetail(id) for id in ids]\n",
    "\n",
    "    def like(self, keyword: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return a list of products that contain the given keyword in their title.\n",
    "        \"\"\"\n",
    "        return [product for product in self.products if keyword in product['product_title']]\n",
    "\n",
    "    def recommend_from_single(self, product_id: str, n=5) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        target_name = self.id_to_productDetail(product_id)['product_title']\n",
    "        keywords = target_name.split(\" \")\n",
    "        recommendations = []\n",
    "        for keyword in keywords:\n",
    "            recommendations.extend(self.like(keyword))\n",
    "        \n",
    "        random.shuffle(recommendations)\n",
    "        return recommendations[:n]\n",
    "\n",
    "    def recommend_from_past(self, user_transactions, n=10) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return recommendations based on past user transactions.\n",
    "        \"\"\"\n",
    "        rec = []\n",
    "        for transaction in user_transactions:\n",
    "            rec.extend(self.recommend_from_single(transaction['product_id']))\n",
    "        random.shuffle(rec)\n",
    "        return rec[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the class using cosine Similarity.\n",
    "\n",
    "class CosineSimilarityRecommender(RecommendationAbstract):\n",
    "    strategy_name: str = \"Cosine Similarity\"\n",
    "    slug_name: str = \"cosine_similarity\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data):\n",
    "        super().__init__(products, product_data)\n",
    "        self.products = products\n",
    "        self.pt = []\n",
    "        self.sim_score = None\n",
    "        \n",
    "    def train(self, transactions, auto_save=True):\n",
    "        self.pt = transactions.pivot_table(index=\"product_id\", columns=\"user_id\", values=\"rate\")\n",
    "        self.pt.fillna(0, inplace=True)\n",
    "        self.sim_score = cosine_similarity(self.pt)\n",
    "        if auto_save:\n",
    "            self.save()\n",
    "        \n",
    "        \n",
    "    def get_filename(self):\n",
    "        return \"models/\" + self.slug_name + self.product_data[\"unique_name\"] + \".pik\"\n",
    "    \n",
    "    def save(self):\n",
    "        # Store self.pt\n",
    "        filename = self.get_filename()\n",
    "        file_simscr = open(filename, 'wb')\n",
    "        pickle.dump(self.sim_score, file_simscr)\n",
    "        file_simscr.close()\n",
    "        \n",
    "    def load(self):\n",
    "        filename = self.get_filename()\n",
    "        file_simscr = open(filename, 'rb')\n",
    "        self.sim_score = pickle.load(file_simscr)\n",
    "        file_simscr.close()\n",
    "        \n",
    "\n",
    "    def recommend_from_single(self, product_id, n=5) -> List[Tuple[dict, float]]:\n",
    "        # print('product_id', product_id, self.products['id'] == product_id)\n",
    "        # Find the index of the product_id in the DataFrame\n",
    "        index = np.where(self.products['id'] == product_id)[0][0]\n",
    "        print('index', index)\n",
    "        # Get similarity scores for the product at the found index\n",
    "        similar_products = sorted(enumerate(self.sim_score[index]), key=lambda x: x[1], reverse=True)[1:n+1]\n",
    "        # Retrieve the similar products using their indices and return them\n",
    "        rec = [self.products.iloc[similar_product[0]] for similar_product in similar_products]\n",
    "        # Gets as list of product dictionary\n",
    "        recomendations_list = []\n",
    "        for product in rec:\n",
    "            recomendations_list.append((product.to_dict(), self.sim_score[index] ))\n",
    "        return recomendations_list\n",
    "\n",
    "\n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        rec = []\n",
    "        for transaction in transactions:\n",
    "            rec.extend(self.recommend_from_single(transaction['product_id']))\n",
    "        random.shuffle(rec)\n",
    "        return rec[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "cosineRecommender = CosineSimilarityRecommender(productdf, product_data)\n",
    "# Train.\n",
    "cosineRecommender.train(transactiondf, auto_save=True)\n",
    "# cosineRecommender.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0449221431',\n",
      " 'product_image': 'http://images.amazon.com/images/P/0449221431.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': 'The Novel James A. Michener Fawcett Books',\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'The Novel'}\n",
      "======== RECOMENDATIONS =========== \n",
      "index 6254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '0671023187',\n",
       "  'product_title': 'Term Limits',\n",
       "  'product_image': 'http://images.amazon.com/images/P/0671023187.01.MZZZZZZZ.jpg',\n",
       "  'product_price': nan,\n",
       "  'product_soup': 'Term Limits Vince Flynn Pocket Star',\n",
       "  'product_tags': nan},\n",
       " {'id': '0553268120',\n",
       "  'product_title': 'All Creatures Great and Small',\n",
       "  'product_image': 'http://images.amazon.com/images/P/0553268120.01.MZZZZZZZ.jpg',\n",
       "  'product_price': nan,\n",
       "  'product_soup': 'All Creatures Great and Small James Herriot Bantam Books',\n",
       "  'product_tags': nan},\n",
       " {'id': '0553254510',\n",
       "  'product_title': 'The Light at the End',\n",
       "  'product_image': 'http://images.amazon.com/images/P/0553254510.01.MZZZZZZZ.jpg',\n",
       "  'product_price': nan,\n",
       "  'product_soup': 'The Light at the End John Skipp Bantam Books',\n",
       "  'product_tags': nan},\n",
       " {'id': '0425117383',\n",
       "  'product_title': 'At Risk',\n",
       "  'product_image': 'http://images.amazon.com/images/P/0425117383.01.MZZZZZZZ.jpg',\n",
       "  'product_price': nan,\n",
       "  'product_soup': 'At Risk Alice Hoffman Berkley Publishing Group',\n",
       "  'product_tags': nan},\n",
       " {'id': '0345333578',\n",
       "  'product_title': 'Palm Beach',\n",
       "  'product_image': 'http://images.amazon.com/images/P/0345333578.01.MZZZZZZZ.jpg',\n",
       "  'product_price': nan,\n",
       "  'product_soup': 'Palm Beach Pat Booth Ballantine Books',\n",
       "  'product_tags': nan}]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use JSON parse.\n",
    "# cosineRecommender.get_random_recommendation()\n",
    "randomid = cosineRecommender.get_random_recommendation()[0]\n",
    "pprint.pprint(randomid)\n",
    "print('======== RECOMENDATIONS =========== ')\n",
    "cosineRecommender.recommend_from_single(randomid['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "class WordVecBodyRecommender(RecommendationAbstract):\n",
    "    \n",
    "    strategy_name: str = \"WordVec\"\n",
    "    slug_name: str = \"wordvec\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data):\n",
    "        \"\"\"\n",
    "        Initialize the recommender with a pre-trained Word2Vec model and a dataframe of books.\n",
    "        \"\"\"\n",
    "        super().__init__(products, product_data)\n",
    "        self.products_df = products\n",
    "        self.model = None\n",
    "        print('id_to_products length', len(self.id_to_products))\n",
    "        self.train()\n",
    "\n",
    "\n",
    "    def train(self, auto_save=True):\n",
    "        \"\"\"\n",
    "        Train the Word2Vec model on the book titles.\n",
    "        \"\"\"\n",
    "        sentences = [title.lower().split() for title in self.products_df['product_soup']]\n",
    "        self.model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "        if auto_save:\n",
    "            self.save()\n",
    "            \n",
    "\n",
    "    def recommend_books_updated(self, input_text, top_n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on input text.\n",
    "        \"\"\"\n",
    "        input_text = input_text.lower().split()\n",
    "        vector = self.model.wv[input_text].mean(axis=0)\n",
    "        # Compute cosine similarity between the input vector and all product vectors\n",
    "        similarities = cosine_similarity([vector], self.model.wv.vectors)\n",
    "        # Get indices of top similar products\n",
    "        top_indices = similarities.argsort()[0][-top_n:]\n",
    "        recommended_products = []\n",
    "        for index in reversed(top_indices):  # Reversed to get top similarities first\n",
    "            product_title = self.products_df.iloc[index]['product_title']\n",
    "            confidence = similarities[0][index]\n",
    "            recommended_products.append((self.id_to_productDetail(self.products_df.iloc[index]['id']), confidence))\n",
    "        return recommended_products\n",
    "\n",
    "        \n",
    "    def recommend_from_single(self, product_id, n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        # Get the product_soup for the given product_id\n",
    "        product_soup = self.products.loc[self.products['id'] == product_id, 'product_soup'].values[0]\n",
    "        # Use the recommend_books_updated function to recommend books based on the product_soup\n",
    "        recommendations = self.recommend_books_updated(product_soup, top_n=n)\n",
    "        return recommendations\n",
    "\n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        \"\"\"\n",
    "        Return recommendations based on past transactions.\n",
    "        \"\"\"\n",
    "        # Concatenate product_soup from past transactions\n",
    "        past_text = ' '.join(self.products.loc[self.products['id'].isin(transactions), 'product_soup'])\n",
    "        # Use the self.recommend_books_updated function to recommend books based on past transactions\n",
    "        recommendations = self.recommend_books_updated(past_text, top_n=n)\n",
    "        return recommendations\n",
    "        \n",
    "        \n",
    "    def get_filename(self):\n",
    "        return  \"models/\" + self.slug_name + self.product_data[\"unique_name\"] + \".model\"\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save the computed book vectors to a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        filemodel = open(filename, 'wb')\n",
    "        pickle.dump(self.model, filemodel)\n",
    "        filemodel.close()\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load the book vectors from a file.\n",
    "        \"\"\"\n",
    "        \n",
    "        filename = self.get_filename()\n",
    "        filemodel = open(filename, 'rb')\n",
    "        self.model = pickle.load(filemodel)\n",
    "        filemodel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_to_products length 13011\n"
     ]
    }
   ],
   "source": [
    "# Implementationa nd test.\n",
    "\n",
    "wordvecRecommender = WordVecBodyRecommender(productdf, product_data)\n",
    "# Train.\n",
    "wordvecRecommender.train()\n",
    "# wordvecRecommender.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0441005993',\n",
      " 'product_image': 'http://images.amazon.com/images/P/0441005993.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': 'The Long Patrol (Redwall, Book 10) Brian Jacques Ace Books',\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'The Long Patrol (Redwall, Book 10)'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'id': '0312421001',\n",
       "   'product_title': \"I Thought My Father Was God: And Other True Tales from NPR's National Story Project\",\n",
       "   'product_image': 'http://images.amazon.com/images/P/0312421001.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': \"I Thought My Father Was God: And Other True Tales from NPR's National Story Project Paul Auster Picador\",\n",
       "   'product_tags': nan},\n",
       "  0.99443233),\n",
       " ({'id': '0060929596',\n",
       "   'product_title': 'As Nature Made Him : The Boy Who Was Raised as a Girl',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0060929596.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'As Nature Made Him : The Boy Who Was Raised as a Girl John Colapinto Perennial',\n",
       "   'product_tags': nan},\n",
       "  0.99420166),\n",
       " ({'id': '039592720X',\n",
       "   'product_title': 'Interpreter of Maladies',\n",
       "   'product_image': 'http://images.amazon.com/images/P/039592720X.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Interpreter of Maladies Jhumpa Lahiri Houghton Mifflin Co',\n",
       "   'product_tags': nan},\n",
       "  0.99378616),\n",
       " ({'id': '0449134482',\n",
       "   'product_title': 'Dances With Wolves',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0449134482.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Dances With Wolves Michael Blake Fawcett Books',\n",
       "   'product_tags': nan},\n",
       "  0.99353707),\n",
       " ({'id': '0449911004',\n",
       "   'product_title': \"Patty Jane's House of Curl (Ballantine Reader's Circle)\",\n",
       "   'product_image': 'http://images.amazon.com/images/P/0449911004.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': \"Patty Jane's House of Curl (Ballantine Reader's Circle) LORNA LANDVIK Ballantine Books\",\n",
       "   'product_tags': nan},\n",
       "  0.9931507)]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get random and recommend.\n",
    "\n",
    "randomProduct = wordvecRecommender.get_random_recommendation()[0]\n",
    "pprint.pprint(randomProduct)\n",
    "wordvecRecommender.recommend_from_single(randomProduct['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TitleWordVecTitleyRecommender(RecommendationAbstract):\n",
    "    \n",
    "    strategy_name: str = \"TitleWordVec\"\n",
    "    slug_name: str = \"title_word_vec\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products, product_data):\n",
    "        \"\"\"\n",
    "        Initialize the recommender with a pre-trained Word2Vec model and a dataframe of books.\n",
    "        \"\"\"\n",
    "        super().__init__(products, product_data)\n",
    "        self.products_df = products\n",
    "        self.model = None\n",
    "        self.train()\n",
    "\n",
    "    def train(self, auto_save=False):\n",
    "        \"\"\"\n",
    "        Train the Word2Vec model on the book titles.\n",
    "        \"\"\"\n",
    "        sentences = [title.lower().split() for title in self.products_df['product_title']]\n",
    "        self.model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "        if auto_save:\n",
    "            self.save()\n",
    "\n",
    "    def recommend_from_single(self, product_id, n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        # Get the product_title for the given product_id\n",
    "        product_title = self.products_df.loc[self.products_df['id'] == product_id, 'product_title'].values[0]\n",
    "        # Use the recommend_books_updated function to recommend books based on the product_title\n",
    "        recommendations = self.recommend_books_updated(product_title, top_n=n)\n",
    "        return recommendations\n",
    "    \n",
    "    def recommend_from_past(self, transactions, n=10):\n",
    "        \"\"\"\n",
    "        Return recommendations based on past transactions.\n",
    "        \"\"\"\n",
    "        # Concatenate product_titles from past transactions\n",
    "        past_titles = self.products_df.loc[self.products_df['id'].isin(transactions), 'product_title']\n",
    "        # Use the self.recommend_books_updated function to recommend books based on past transactions\n",
    "        recommendations = self.recommend_books_updated(' '.join(past_titles), top_n=n)\n",
    "        return recommendations\n",
    "\n",
    "        \n",
    "\n",
    "    def recommend_books_updated(self, input_text, top_n=5):\n",
    "        \"\"\"\n",
    "        Return recommendations based on input text.\n",
    "        \"\"\"\n",
    "        input_text = input_text.lower().split()\n",
    "        vector = self.model.wv[input_text].mean(axis=0)\n",
    "        # Compute cosine similarity between the input vector and all product vectors\n",
    "        similarities = cosine_similarity([vector], self.model.wv.vectors)\n",
    "        # Get indices of top similar products\n",
    "        top_indices = similarities.argsort()[0][-top_n:]\n",
    "        recommended_products = []\n",
    "        for index in reversed(top_indices):  # Reversed to get top similarities first\n",
    "            product_title = self.products_df.iloc[index]['product_title']\n",
    "            confidence = similarities[0][index]\n",
    "            recommended_products.append((self.id_to_productDetail(self.products_df.iloc[index]['id']), confidence))\n",
    "        return recommended_products\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save the computed book vectors to a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        with open(filename, 'wb') as filemodel:\n",
    "            pickle.dump(self.model, filemodel)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load the book vectors from a file.\n",
    "        \"\"\"\n",
    "        filename = self.get_filename()\n",
    "        with open(filename, 'rb') as filemodel:\n",
    "            self.model = pickle.load(filemodel)\n",
    "\n",
    "    def get_filename(self):\n",
    "        \"\"\"\n",
    "        Get the filename for saving/loading the model.\n",
    "        \"\"\"\n",
    "        return \"models/\" + self.slug_name + self.product_data[\"unique_name\"] + \".model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random and recommend.\n",
    "wordvecRecommender = TitleWordVecTitleyRecommender(productdf, product_data)\n",
    "# Train.\n",
    "wordvecRecommender.train( auto_save=True)\n",
    "# wordvecRecommender.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1400031362',\n",
      " 'product_image': 'http://images.amazon.com/images/P/1400031362.01.MZZZZZZZ.jpg',\n",
      " 'product_price': nan,\n",
      " 'product_soup': 'Morality for Beautiful Girls (No.1 Ladies Detective Agency) '\n",
      "                 'Alexander McCall Smith Anchor',\n",
      " 'product_tags': nan,\n",
      " 'product_title': 'Morality for Beautiful Girls (No.1 Ladies Detective Agency)'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'id': '0375406328',\n",
       "   'product_title': 'Lying Awake',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0375406328.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Lying Awake Mark Salzman Alfred A. Knopf',\n",
       "   'product_tags': nan},\n",
       "  0.9998026),\n",
       " ({'id': '0452264464',\n",
       "   'product_title': 'Beloved (Plume Contemporary Fiction)',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0452264464.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Beloved (Plume Contemporary Fiction) Toni Morrison Plume',\n",
       "   'product_tags': nan},\n",
       "  0.9996399),\n",
       " ({'id': '0345417623',\n",
       "   'product_title': 'Timeline',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0345417623.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Timeline MICHAEL CRICHTON Ballantine Books',\n",
       "   'product_tags': nan},\n",
       "  0.999609),\n",
       " ({'id': '0394895894',\n",
       "   'product_title': 'The Ruby in the Smoke (Sally Lockhart Trilogy, Book 1)',\n",
       "   'product_image': 'http://images.amazon.com/images/P/0394895894.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'The Ruby in the Smoke (Sally Lockhart Trilogy, Book 1) PHILIP PULLMAN Laurel Leaf',\n",
       "   'product_tags': nan},\n",
       "  0.99960256),\n",
       " ({'id': '042518630X',\n",
       "   'product_title': 'Purity in Death',\n",
       "   'product_image': 'http://images.amazon.com/images/P/042518630X.01.MZZZZZZZ.jpg',\n",
       "   'product_price': nan,\n",
       "   'product_soup': 'Purity in Death J.D. Robb Berkley Publishing Group',\n",
       "   'product_tags': nan},\n",
       "  0.99958634)]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tansactions = ['1551665204', '055357538']\n",
    "\n",
    "randomProduct = wordvecRecommender.get_random_recommendation()[0]\n",
    "pprint.pprint(randomProduct)\n",
    "wordvecRecommender.recommend_from_single(randomProduct['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
