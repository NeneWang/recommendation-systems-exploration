{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                      product_title  \\\n",
      "0  0002005018                                       Clara Callan   \n",
      "1  0399135782                             The Kitchen God's Wife   \n",
      "2  0440234743                                      The Testament   \n",
      "3  0452264464               Beloved (Plume Contemporary Fiction)   \n",
      "4  0609804618  Our Dumb Century: The Onion Presents 100 Years...   \n",
      "\n",
      "                                       product_image  product_price  \\\n",
      "0  http://images.amazon.com/images/P/0002005018.0...            NaN   \n",
      "1  http://images.amazon.com/images/P/0399135782.0...            NaN   \n",
      "2  http://images.amazon.com/images/P/0440234743.0...            NaN   \n",
      "3  http://images.amazon.com/images/P/0452264464.0...            NaN   \n",
      "4  http://images.amazon.com/images/P/0609804618.0...            NaN   \n",
      "\n",
      "                                        product_soup  product_tags  \n",
      "0  Clara Callan Richard Bruce Wright HarperFlamin...           NaN  \n",
      "1    The Kitchen God's Wife Amy Tan Putnam Pub Group           NaN  \n",
      "2                    The Testament John Grisham Dell           NaN  \n",
      "3  Beloved (Plume Contemporary Fiction) Toni Morr...           NaN  \n",
      "4  Our Dumb Century: The Onion Presents 100 Years...           NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/products_books_v1_10_10.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'vector_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [row\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_soup\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train Word2Vec model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mWord2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Save the model for later use\u001b[39;00m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/book_wordvec.model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'vector_size'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess text data\n",
    "data['processed_soup'] = data['product_soup'].str.lower().str.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Prepare data for Word2Vec model\n",
    "sentences = [row.split() for row in data['processed_soup'].dropna()]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Save the model for later use\n",
    "model.save(\"../data/book_wordvec.model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clara Callan',\n",
       " 'Cunt: A Declaration of Independence (Live Girls)',\n",
       " 'Callander Square',\n",
       " 'Cunt: A Declaration of Independence (Live Girls Series)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updated function to recommend books based on similar word vectors\n",
    "def recommend_books_updated(input_text, top_n=5):\n",
    "    input_text = input_text.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    vector = model.wv[input_text].mean(axis=0)\n",
    "    similar_vectors = model.wv.similar_by_vector(vector, topn=top_n + 10)  # Retrieve more results to filter unique titles\n",
    "    recommended_titles = []\n",
    "    for book_vector in similar_vectors:\n",
    "        similar_title = data.loc[data['processed_soup'].apply(lambda x: any(word in x for word in input_text)), 'product_title'].unique()\n",
    "        for title in similar_title:\n",
    "            if title not in recommended_titles and len(recommended_titles) < top_n:\n",
    "                recommended_titles.append(title)\n",
    "    return recommended_titles\n",
    "\n",
    "\n",
    "# Test the updated function with the same book title\n",
    "recommend_books_updated(\"Clara Callan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New Vegetarian: Bold and Beautiful Recipes for Every Occasion',\n",
       " 'Prague : A Novel',\n",
       " 'Seabiscuit: An American Legend',\n",
       " 'Pigs in Heaven',\n",
       " 'This Year It Will Be Different: And Other Stories']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test the updated function Kings the same book title\n",
    "recommend_books_updated(\"Pale Kings and Prince\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pigs in Heaven',\n",
       " 'Poisonwood Bible Edition Uk',\n",
       " 'The Game of Kings (Lymond Chronicles, 1)',\n",
       " 'The Bean Trees',\n",
       " 'Homeland and Other Stories']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test the updated function Kings the same book title\n",
    "recommend_books_updated(\"Kings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pale Fire: A Novel (Vintage International)',\n",
       " 'On a Pale Horse',\n",
       " 'Pale Horse Coming',\n",
       " 'Pale Kings and Princes',\n",
       " 'On a Pale Horse (Incarnations of Immortality, Bk. 1)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test the updated function Kings the same book title\n",
    "recommend_books_updated(\"Pale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from summa import keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input sentence\n",
    "sentence = \"\"\"He is the King\"\"\"\n",
    "\n",
    "# Extract keywords using TextRank algorithm\n",
    "keywords_list = keywords.keywords(sentence, words=3)\n",
    "\n",
    "print(\"Keywords:\", keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import keywords\n",
    "\n",
    "# Example text\n",
    "text = \"Pale Kings and Prince\"\n",
    "\n",
    "# Getting keywords\n",
    "key_words = keywords(text)\n",
    "\n",
    "print(key_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drug\n",
      "spenser\n",
      "sans\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import keywords\n",
    "\n",
    "# Example text\n",
    "text = \"Pale Kings and Princes is a Spenser novel by Robert B. Parker. The title is taken from John Keats's poem La Belle Dame sans Merci: A Ballad. Following the murder of a reporter, Spenser is hired by a newspaper to investigate drug smuggling around the area of Wheaton, Massachusetts.\"\"\"\n",
    "\n",
    "# Getting keywords\n",
    "key_words = keywords(text)\n",
    "\n",
    "print(key_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouns: ['Kings']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English tokenizer, tagger, parser, NER, and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Your text\n",
    "text = \"Pale Kings and Prince\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract nouns\n",
    "nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
    "\n",
    "print(\"Nouns:\", nouns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
