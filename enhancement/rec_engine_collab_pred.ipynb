{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "import random\n",
    "import pickle\n",
    "import pprint\n",
    "import spacy\n",
    "\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "\n",
    "product_data = {\n",
    "    \"data_context\": \"books\",\n",
    "    \"product_filepath\": \"data/products_books_v1_10_10.csv\",\n",
    "    \"transactions_filepath\": \"data/transactions_books_v1_10_10.csv\",\n",
    "    \"features\": [\"product_title\", \"product_image\", \"product_soup\", \"product_images\"],\n",
    "    \"version\": \"1.0\",\n",
    "    \"unique_name\": \"_books_v1_10_10\",\n",
    "}\n",
    "\n",
    "print(\"looking at\", \"../\" + product_data[\"product_filepath\"])\n",
    "\n",
    "productdf =  pd.read_csv(\"../\" + product_data[\"product_filepath\"])\n",
    "transactiondf = pd.read_csv(\"../\" + product_data[\"transactions_filepath\"])\n",
    "\n",
    "\n",
    "print(len(transactiondf))\n",
    "productdf.head()\n",
    "transactiondf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RecommendationAbstract():\n",
    "    strategy_name: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    version: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_past_recommendation: bool = \"REQUIRES IMPLEMENTATION\"\n",
    "\n",
    "    def __init__(self, products, product_data):\n",
    "        self.products = products\n",
    "        self.product_data = product_data\n",
    "        self.model = None\n",
    "        # populate id_to_products\n",
    "        self.id_to_products = {}\n",
    "        for product in self.products.to_dict(orient='records'):\n",
    "            self.id_to_products[product['id']] = product\n",
    "\n",
    "    def loadModel(self, model_code):\n",
    "        \"\"\"\n",
    "        Load the model\n",
    "        \"\"\"\n",
    "        self.model = model_code\n",
    "\n",
    "    def train(self, verbose=False, transactions_train=None, users_train=None):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        # ... do training\n",
    "        # self.model = trained_model\n",
    "        \n",
    "    def get_random_recommendation(self, n=1):\n",
    "        \"\"\"\n",
    "        Get random recommendations\n",
    "        \"\"\"\n",
    "        # Select n random rows from the DataFrame\n",
    "        random_rows = self.products.sample(n)\n",
    "        # Convert the selected rows to a list of dictionaries\n",
    "        random_recommendations = random_rows.to_dict(orient='records')\n",
    "        return random_recommendations\n",
    "\n",
    "\n",
    "\n",
    "    def saveModel(self, model_code):\n",
    "        \"\"\"\n",
    "        Save the model\n",
    "        \"\"\"\n",
    "        # ... saves the model\n",
    "\n",
    "    def id_to_productDetail(self, product_id: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Return product details based on product id.\n",
    "        \"\"\"\n",
    "        return self.id_to_products.get(product_id)\n",
    "\n",
    "    def ids_to_products(self, ids: List[str]) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Return product details for a list of product ids.\n",
    "        \"\"\"\n",
    "        return [self.id_to_productDetail(id) for id in ids]\n",
    "\n",
    "    def like(self, keyword: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return a list of products that contain the given keyword in their title.\n",
    "        \"\"\"\n",
    "        return [product for product in self.products if keyword in product['product_title']]\n",
    "\n",
    "    def recommend_from_single(self, product_id: str, n=5) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return recommendations based on a single product.\n",
    "        \"\"\"\n",
    "        target_name = self.id_to_productDetail(product_id)['product_title']\n",
    "        keywords = target_name.split(\" \")\n",
    "        recommendations = []\n",
    "        for keyword in keywords:\n",
    "            recommendations.extend(self.like(keyword))\n",
    "        \n",
    "        random.shuffle(recommendations)\n",
    "        return recommendations[:n]\n",
    "\n",
    "    def recommend_from_past(self, user_transactions, n=10) -> List[str]:\n",
    "        \"\"\"\n",
    "        Return recommendations based on past user transactions.\n",
    "        \"\"\"\n",
    "        rec = []\n",
    "        for transaction in user_transactions:\n",
    "            rec.extend(self.recommend_from_single(transaction['product_id']))\n",
    "        random.shuffle(rec)\n",
    "        return rec[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from surprise import KNNWithZScore\n",
    "\n",
    "class KNNWithZScoreRecommender(RecommendationAbstract):\n",
    "    strategy_name: str = \"KNN With Means\"\n",
    "    slug_name: str = \"knn_with_means\"\n",
    "    version: str = \"v1\"\n",
    "    details: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    link: str = \"REQUIRES IMPLEMENTATION\"\n",
    "    supports_single_recommendation: bool = True\n",
    "    supports_past_recommendation: bool = True\n",
    "    \n",
    "    def __init__(self, products: pd.DataFrame, product_data: dict):\n",
    "        super().__init__(products, product_data)\n",
    "        self.products = products\n",
    "        self.model = None\n",
    "        \n",
    "        # Get the product ids and store them.\n",
    "        self.product_ids = self.products['id'].unique()\n",
    "        self.all_transactions_df = None\n",
    "        \n",
    "    def train(self, transactions, auto_save=True, dont_save_self_state=False) :\n",
    "        \n",
    "        sim_options = {\"name\": \"pearson_baseline\", \"user_based\": False}\n",
    "        model = KNNWithZScore(sim_options=sim_options)\n",
    "        \n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        \n",
    "        data = Dataset.load_from_df(transactions[['user_id', 'product_id', 'rate']], reader)\n",
    "        \n",
    "        model.fit(data.build_full_trainset())\n",
    "        \n",
    "        if dont_save_self_state:\n",
    "            return model\n",
    "        \n",
    "        self.model = model\n",
    "        self.all_transactions_df = transactions\n",
    "        # self.accuracy = accuracy.rmse(model.test(data.build_full_trainset().build_testset()), verbose=True)\n",
    "        \n",
    "        if auto_save:\n",
    "            self.save()\n",
    "            \n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def get_filename(self):\n",
    "        return \"models/\" + self.slug_name + self.product_data[\"unique_name\"] + \".pik\"\n",
    "    \n",
    "    def save(self):\n",
    "        # Store self.pt\n",
    "        filename = self.get_filename()\n",
    "        model_file = open(filename, 'wb')\n",
    "        pickle.dump(self.model, model_file)\n",
    "        model_file.close()\n",
    "        \n",
    "    def load(self):\n",
    "        filename = self.get_filename()\n",
    "        model_file = open(filename, 'rb')\n",
    "        self.model = pickle.load(model_file)\n",
    "        model_file.close()\n",
    "        \n",
    "\n",
    "    def recommend_from_single(self, product_id: str, n=5) -> List[Tuple[dict, float]]:\n",
    "        \"\"\"\n",
    "        \n",
    "        # Retrieve inner ids of the nearest neighbors of Toy Story.\n",
    "        toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=10)\n",
    "        \"\"\"\n",
    "        recommendation_list: List[tuple[dict, float]] = []\n",
    "        \n",
    "        product_inner_id = self.model.trainset.to_inner_iid(product_id)\n",
    "        \n",
    "        neighbors = self.model.get_neighbors(product_inner_id, k=n)\n",
    "        \n",
    "        for neighbor in neighbors:\n",
    "            product_serie = self.products.iloc[neighbor]\n",
    "            product = product_serie.to_dict()\n",
    "            recommendation_list.append((product, 1.0))\n",
    "        \n",
    "        return recommendation_list[:n]\n",
    "\n",
    "    def collaborativestore_predict_population(self, transactions: List[str], n=5):\n",
    "        \"\"\"\n",
    "        Adds the transactions to the use history\n",
    "        'user_id', 'product_id', 'rate'\n",
    "        \"\"\"\n",
    "        # Add transactions to the self.transactions_df as a new user\n",
    "        transaction_rows = []\n",
    "        random_user_id = \"user\" + str(random.randint(0, 1000000))\n",
    "        for transaction in transactions:\n",
    "            transaction_rows.append({'user_id': 'user_id', 'product_id': transaction, 'rate': 5})\n",
    "        \n",
    "        # Convert to a DataFrame\n",
    "        new_transactions_df = pd.DataFrame(transaction_rows)\n",
    "\n",
    "        # Append using concat\n",
    "        all_transactions_df: pd.Dataframe = pd.concat([self.all_transactions_df, new_transactions_df], ignore_index=True)\n",
    "        \n",
    "        model = self.train(all_transactions_df, dont_save_self_state=True)\n",
    "        \n",
    "        return self.predict_recommendations(random_user_id, transactions, model, n)\n",
    "    \n",
    "    def predict_recommendations(self, user_id: str, transactions: List[str], model, n=5):\n",
    "        books_to_predict = [book_id for book_id in self.product_ids if book_id not in transactions]\n",
    "        predictions = []\n",
    "        \n",
    "        for book_id in books_to_predict:\n",
    "            pred = model.predict(user_id, book_id)\n",
    "            predictions.append((book_id, pred.est))\n",
    "        \n",
    "        pred_products = []\n",
    "        # sort predictions\n",
    "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "        for book_id, confidence in predictions[:n]:\n",
    "            product = self.id_to_products[book_id]\n",
    "            pred_products.append(product)\n",
    "            \n",
    "        return pred_products\n",
    "        \n",
    "\n",
    "    def recommend_from_past(self, transactions: List[str], n=10):\n",
    "        \"\"\"\n",
    "        Calls for each transaction the recommend_from_single method.\n",
    "        Gives Priority if seen multiple recommendations.\n",
    "        Shuffle and returns :n\n",
    "        \"\"\"\n",
    "        recs = set()\n",
    "        recs_seen_times = {}\n",
    "        products_dictionary = {}\n",
    "        \n",
    "        if(len(transactions) > 2):\n",
    "            return self.collaborativestore_predict_population(\n",
    "                transactions, n=n\n",
    "            )\n",
    "        \n",
    "        for transaction in transactions:\n",
    "            recs = self.recommend_from_single(transaction)\n",
    "            for rec_id, confidence in recs:\n",
    "                \n",
    "                if rec_id in recs:\n",
    "                    recs_seen_times[rec_id['id']] += 1\n",
    "                else:\n",
    "                    products_dictionary[rec_id['id']] = rec_id\n",
    "                    recs_seen_times[rec_id['id']] = 1\n",
    "        \n",
    "        for rec_id in recs_seen_times:\n",
    "            recs.append((products_dictionary[rec_id], recs_seen_times[rec_id]))\n",
    "            \n",
    "        recs = list(recs)\n",
    "        # sort\n",
    "        \n",
    "        recs.sort(key=lambda x: x[1], reverse=True)\n",
    "        return recs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engineRec = KNNWithZScoreRecommender(productdf, product_data)\n",
    "engineRec.train(transactions=transactiondf, auto_save=True)\n",
    "# engineRec.load()\n",
    "  \n",
    "  \n",
    "\n",
    "randomProduct = engineRec.get_random_recommendation()[0]\n",
    "pprint.pprint(randomProduct)\n",
    "\n",
    "print('======== RECOMENDATIONS SINGLE CASE =========== ')\n",
    "rec = engineRec.recommend_from_single(randomProduct['id'])\n",
    "pprint.pprint(rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
