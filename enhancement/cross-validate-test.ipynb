{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9378  0.9345  0.9348  0.9336  0.9404  0.9362  0.0025  \n",
      "MAE (testset)     0.7383  0.7388  0.7327  0.7345  0.7420  0.7373  0.0033  \n",
      "Fit time          0.73    1.01    0.86    0.78    0.91    0.86    0.10    \n",
      "Test time         0.10    0.14    0.07    0.11    0.20    0.12    0.04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93776726, 0.93452654, 0.93480415, 0.93355821, 0.94035598]),\n",
       " 'test_mae': array([0.7382759 , 0.73881273, 0.73268252, 0.73451274, 0.74200493]),\n",
       " 'fit_time': (0.7338352203369141,\n",
       "  1.0080935955047607,\n",
       "  0.8636116981506348,\n",
       "  0.7758738994598389,\n",
       "  0.9141237735748291),\n",
       " 'test_time': (0.10041522979736328,\n",
       "  0.13884282112121582,\n",
       "  0.07244348526000977,\n",
       "  0.10793089866638184,\n",
       "  0.20364856719970703)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed),\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Use movielens-100K\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "param_grid = {\"n_epochs\": [5, 10], \"lr_all\": [0.002, 0.005], \"reg_all\": [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score[\"rmse\"])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score. At the moment, will just have thm using default. \n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What parameters is it perfecting?\n",
    "\n",
    "```bash\n",
    "0.9644011736716195\n",
    "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n",
    "```\n",
    "\n",
    "- Are they shared across all? \n",
    "- Do I have to Define by each algorithm the type of `grid search` parameters to look up with?\n",
    "This seems to be the best configuration:\n",
    "\n",
    "\n",
    "I dont think so, They should be diff, based on the specific algorithm.\n",
    "Therefore they should be also added to the parameters\n",
    "\n",
    "```\n",
    "classsurprise.prediction_algorithms.matrix_factorization.SVD(n_factors=100, n_epochs=20, biased=True, init_mean=0, init_std_dev=0.1, lr_all=0.005, reg_all=0.02, lr_bu=None, lr_bi=None, lr_pu=None, lr_qi=None, reg_bu=None, reg_bi=None, reg_pu=None, reg_qi=None, random_state=None, verbose=False)\n",
    "```\n",
    "\n",
    "```\n",
    "bsl_options = {\"method\": \"als\", \"n_epochs\": 5, \"reg_u\": 12, \"reg_i\": 5}\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1f800f7ed30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now use the algorithm that yields the best rmse:\n",
    "algo = gs.best_estimator[\"rmse\"]\n",
    "algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.9867083136903169\n",
      "{'k': 40, 'min_k': 2}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use movielens-100K\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "from surprise import Dataset, KNNBasic\n",
    "\n",
    "param_grid = {\"k\": [40, 42], \"min_k\": [2, 3]}\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=[\"rmse\", \"mae\"], cv=3, return_train_measures=True)\n",
    "\n",
    "gs.fit(data)x\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score[\"rmse\"])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now use the algorithm that yields the best rmse:\n",
    "algo = gs.best_estimator[\"rmse\"]\n",
    "algo.fit(data.build_full_trainset())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
