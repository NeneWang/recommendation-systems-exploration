{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to C:\\Users\\wangn/.surprise_data/ml-100k\n",
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9397  0.9371  0.9374  0.9297  0.9333  0.9355  0.0035  \n",
      "MAE (testset)     0.7382  0.7402  0.7367  0.7334  0.7366  0.7370  0.0022  \n",
      "Fit time          0.67    0.71    0.67    0.68    0.70    0.69    0.01    \n",
      "Test time         0.08    0.11    0.11    0.11    0.08    0.10    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93973968, 0.93708205, 0.93738551, 0.92974879, 0.93332395]),\n",
       " 'test_mae': array([0.7382153 , 0.74023018, 0.73667017, 0.73339469, 0.73659523]),\n",
       " 'fit_time': (0.6740007400512695,\n",
       "  0.7069995403289795,\n",
       "  0.6719989776611328,\n",
       "  0.6839985847473145,\n",
       "  0.7010021209716797),\n",
       " 'test_time': (0.07899951934814453,\n",
       "  0.11099982261657715,\n",
       "  0.11099839210510254,\n",
       "  0.11299896240234375,\n",
       "  0.07899808883666992)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed),\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9638571423110456\n",
      "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Use movielens-100K\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "param_grid = {\"n_epochs\": [5, 10], \"lr_all\": [0.002, 0.005], \"reg_all\": [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score[\"rmse\"])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score. At the moment, will just have thm using default. \n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What parameters is it perfecting?\n",
    "\n",
    "```bash\n",
    "0.9644011736716195\n",
    "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n",
    "```\n",
    "\n",
    "- Are they shared across all? \n",
    "- Do I have to Define by each algorithm the type of `grid search` parameters to look up with?\n",
    "This seems to be the best configuration:\n",
    "\n",
    "\n",
    "I dont think so, They should be diff, based on the specific algorithm.\n",
    "Therefore they should be also added to the parameters\n",
    "\n",
    "```\n",
    "classsurprise.prediction_algorithms.matrix_factorization.SVD(n_factors=100, n_epochs=20, biased=True, init_mean=0, init_std_dev=0.1, lr_all=0.005, reg_all=0.02, lr_bu=None, lr_bi=None, lr_pu=None, lr_qi=None, reg_bu=None, reg_bi=None, reg_pu=None, reg_qi=None, random_state=None, verbose=False)\n",
    "```\n",
    "\n",
    "```\n",
    "bsl_options = {\"method\": \"als\", \"n_epochs\": 5, \"reg_u\": 12, \"reg_i\": 5}\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x21adce305b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now use the algorithm that yields the best rmse:\n",
    "algo = gs.best_estimator[\"rmse\"]\n",
    "algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.986698912960084\n",
      "{'k': 40, 'min_k': 2}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use movielens-100K\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "from surprise import Dataset, KNNBasic\n",
    "\n",
    "param_grid = {\"k\": [40, 42], \"min_k\": [2, 3]}\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=[\"rmse\", \"mae\"], cv=3, return_train_measures=True)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score[\"rmse\"])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x21adcdf3550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now use the algorithm that yields the best rmse:\n",
    "algo = gs.best_estimator[\"rmse\"]\n",
    "algo.fit(data.build_full_trainset())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
